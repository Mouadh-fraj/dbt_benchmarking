{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c989f41",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Title](images/title-page.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90ad24f-5035-4c5d-81e4-a81d9dff1e9a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Title](images/title-qr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed161285-5c6c-41de-a4ad-685a5de5ba0e",
   "metadata": {},
   "source": [
    "### What is the TPC?\n",
    "The TPC is a non-profit corporation focused on developing data-centric benchmark standards and disseminating objective, verifiable data to the industry.\n",
    "\n",
    "### What is TPC-DI?\n",
    "The TPC-DI benchmark combines and transforms data extracted from an On-Line Transaction Processing (OTLP) system along with other sources of data, and loads it into a data warehouse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a9e518-484a-4f18-80d4-4ae43c72312a",
   "metadata": {},
   "source": [
    "![ETL Diagram](images/tpc-di-etl-diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TPC-DI provides `DIGen.jar` to generate the source files.\n",
    "\n",
    "The JAR is dated and requires a 1.8 JDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: DIGen\n",
      " -h                   print this message\n",
      " -jvm <JVM options>   JVM options. E.g. -jvm \"-Xms1g -Xmx2g\"\n",
      " -o <directory>       Specify output directory.  Default is output.\n",
      " -sf <sf>             Scale factor.  Default value is 5. (range: 3 -\n",
      "                      2147483647\n",
      " -v                   print DIGen version\n"
     ]
    }
   ],
   "source": [
    "!jenv local 1.8\n",
    "!java -jar ~/dev/Tools/DIGen.jar --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/stewartbryson/dev/tpcdi-output\n",
      "########################################################################################################################\n",
      "                                                  PDGF v2.5_#1343_b4177\n",
      "                                            Parallel Data Generation Framework\n",
      "                (c)bankmark UG (haftungsbeschraenkt), Frank M., Danisch M., Rabl T. http://www.bankmark.de\n",
      "########################################################################################################################\n",
      "                                                   License information\n",
      "                            The Software is provided to you as part of the TPC Benchmark DI. \n",
      " When using this software you must agree to the license provided in LICENSE.TXT of this package. Use is restricted to TPC\n",
      "DI benchmarking purposes as specified in LICENSE.TXT. If you would like to use the software for other purposes, you must\n",
      "contact bankmark UG (haftungsbeschraenkt) (http://www.bankmark.de) to purchase a fully licensed copy of the Software.\n",
      "########################################################################################################################\n",
      "for a command overview start with commandline parameter: -help\n",
      "or type \"help\" in the built in shell: PDGF:> \n",
      "\n",
      "Set closeWhenDone from: false to: true\n",
      "Set project main scale factor from -notSet- to 5000.0\n",
      "Set default output path to:\"/Users/stewartbryson/dev/tpcdi-output/\"\n",
      "Loading configuration files ...\n",
      "23: XML <property name=\"SF\">5000.0 was already defined in config file or is manually overridden by a user set commandline argument. Currently assigned value: '5000.0' and will remain unchanged at this value\n",
      "Registered Generation event listner: tpc.di.output.AuditTotalRecordsSummaryWriter\n",
      "Loading successful.\n",
      "All required configuration files are loaded. You may start the generation process.\n",
      "Initializing system...\n",
      "Node 1 Worker count was not specified. Detected 8 available processors and start now same amount of workers\n",
      "FinWireFinBlackBox.initialize() LAST UPDATE ID: 202\n",
      "DailyMarketBlackBox.initialize() LAST UPDATE ID: 733\n",
      "initializing WatchHistoryBlackBox of table: 'WatchHistory'... done\n",
      "Cloning data structures for parallelization...\n",
      "Clone time 0h:00m:00s:153ms\n",
      "initialized 0h:00m:00s:333ms\n",
      "Starting data generation proccess...\n",
      "Startuptime: 0h:00m:00s:976ms\n",
      "FileChannelProvider is: pdgf.util.caching.fileWriter.OutputFileWriter$DefaultFileChannelProvider\n",
      "\n",
      "generating 1/16 \"StatusType\"\t  rows: 1-6 of 6\n",
      "\n",
      "PDGF:> finished  1/16 \"StatusType\"\t  in: 0h:00m:00s:008ms total size: 3.6 KiB average speed: 454.7 KiB/s\n",
      "\n",
      "generating 2/16 \"TaxRate\"\t  rows: 1-320 of 320\n",
      "finished  2/16 \"TaxRate\"\t  in: 0h:00m:00s:005ms total size: 16.7 KiB average speed: 3.3 MiB/s\n",
      "\n",
      "generating 3/16 \"Date\"\t  rows: 1-25933 of 25933\n",
      "finished  3/16 \"Date\"\t  in: 0h:00m:00s:416ms total size: 3.3 MiB average speed: 8.0 MiB/s\n",
      "\n",
      "generating 4/16 \"Time\"\t  rows: 1-86400 of 86400\n",
      "finished  4/16 \"Time\"\t  in: 0h:00m:00s:127ms total size: 4.6 MiB average speed: 35.9 MiB/s\n",
      "\n",
      "generating 5/16 \"BatchDate\"\t  update: historical\n",
      "finished  5/16 \"BatchDate\"\t  in: 0h:00m:00s:004ms total size: 88 B average speed: 21.5 KiB/s\n",
      "\n",
      "generating 6/16 \"HR\"\t  rows: 1-25000 of 25000\n",
      "finished  6/16 \"HR\"\t  in: 0h:00m:00s:048ms total size: 1.9 MiB average speed: 40.1 MiB/s\n",
      "\n",
      "generating 7/16 \"CustomerMgmt\"\t  update: historical\n",
      "finished  7/16 \"CustomerMgmt\"\t  in: 0h:00m:00s:399ms total size: 14.9 MiB average speed: 37.3 MiB/s\n",
      "\n",
      "generating 8/16 \"Customer\"\t  update: 431/432\n",
      "finished  8/16 \"Customer\"\t  in: 0h:00m:00s:005ms total size: 10.6 KiB average speed: 2.1 MiB/s\n",
      "\n",
      "generating 9/16 \"Account\"\t  update: 431/432\n",
      "finished  9/16 \"Account\"\t  in: 0h:00m:00s:003ms total size: 7.2 KiB average speed: 2.3 MiB/s\n",
      "\n",
      "generating 10/16 \"Prospect\"\t  update: historical\n",
      "finished  10/16 \"Prospect\"\t  in: 0h:00m:00s:194ms total size: 14.9 MiB average speed: 76.7 MiB/s\n",
      "\n",
      "generating 11/16 \"Industry\"\t  rows: 1-102 of 102\n",
      "finished  11/16 \"Industry\"\t  in: 0h:00m:00s:002ms total size: 2.7 KiB average speed: 1.3 MiB/s\n",
      "\n",
      "generating 12/16 \"FINWIRE\"\t  update: historical\n",
      "finished  12/16 \"FINWIRE\"\t  in: 0h:00m:00s:526ms total size: 44.2 MiB average speed: 84.0 MiB/s\n",
      "\n",
      "generating 13/16 \"DailyMarket\"\t  update: historical\n",
      "finished  13/16 \"DailyMarket\"\t  in: 0h:00m:01s:232ms total size: 136.1 MiB average speed: 110.5 MiB/s\n",
      "\n",
      "generating 14/16 \"WatchHistory\"\t  update: historical\n",
      "finished  14/16 \"WatchHistory\"\t  in: 0h:00m:00s:675ms total size: 66.9 MiB average speed: 99.1 MiB/s\n",
      "\n",
      "generating 15/16 \"TradeSource\"\t  update: historical\n",
      "finished  15/16 \"TradeSource\"\t  in: 0h:00m:02s:060ms total size: 177.0 MiB average speed: 85.9 MiB/s\n",
      "\n",
      "generating 16/16 \"TradeType\"\t  rows: 1-5 of 5\n",
      "All work done\n",
      "Data generation finished successfully\n",
      "AuditTotalRecordsSummaryWriter - TotalRecords for Batch1: 7804509\n",
      "AuditTotalRecordsSummaryWriter - TotalRecords for Batch2: 33380\n",
      "AuditTotalRecordsSummaryWriter - TotalRecords for Batch3: 33455\n",
      "AuditTotalRecordsSummaryWriter - TotalRecords all Batches: 7871344 1373947.29 records/second\n",
      "Statistics  \n",
      "=========\n",
      "Overall time\t0h:00m:05s:728ms\n",
      "Generated\t463.9 MiB\n",
      "Speed\t\t81.0 MiB/s\n",
      "\n",
      "DIGen completed successfully.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ~/dev/tpcdi-output\n",
    "!mkdir -p ~/dev/tpcdi-output\n",
    "!cd ~/dev/Tools && java -jar ~/dev/Tools/DIGen.jar -o ~/dev/tpcdi-output -sf 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The GitHub repository has a prebuilt CLI for easily loading the files.\n",
    "### https://github.com/stewartbryson/dbt-tpcdi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m                                                                                \u001b[0m\n",
      "\u001b[1m \u001b[0m\u001b[1;33mUsage: \u001b[0m\u001b[1mtpcdi.py [OPTIONS] COMMAND [ARGS]...\u001b[0m\u001b[1m                                   \u001b[0m\u001b[1m \u001b[0m\n",
      "\u001b[1m                                                                                \u001b[0m\n",
      " A utility for loading TPC-DI generated files into Snowflake.                   \n",
      "                                                                                \n",
      "\u001b[2m╭─\u001b[0m\u001b[2m Options \u001b[0m\u001b[2m───────────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "\u001b[2m│\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-install\u001b[0m\u001b[1;36m-completion\u001b[0m        \u001b[1;2;33m[\u001b[0m\u001b[1;33mbash\u001b[0m\u001b[1;2;33m|\u001b[0m\u001b[1;33mzsh\u001b[0m\u001b[1;2;33m|\u001b[0m\u001b[1;33mfish\u001b[0m\u001b[1;2;33m|\u001b[0m\u001b[1;33mpowershe\u001b[0m  Install completion for  \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                             \u001b[1;33mll\u001b[0m\u001b[1;2;33m|\u001b[0m\u001b[1;33mpwsh\u001b[0m\u001b[1;2;33m]\u001b[0m\u001b[1;33m               \u001b[0m  the specified shell.    \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                      \u001b[2m[default: None]        \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-show\u001b[0m\u001b[1;36m-completion\u001b[0m           \u001b[1;2;33m[\u001b[0m\u001b[1;33mbash\u001b[0m\u001b[1;2;33m|\u001b[0m\u001b[1;33mzsh\u001b[0m\u001b[1;2;33m|\u001b[0m\u001b[1;33mfish\u001b[0m\u001b[1;2;33m|\u001b[0m\u001b[1;33mpowershe\u001b[0m  Show completion for the \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                             \u001b[1;33mll\u001b[0m\u001b[1;2;33m|\u001b[0m\u001b[1;33mpwsh\u001b[0m\u001b[1;2;33m]\u001b[0m\u001b[1;33m               \u001b[0m  specified shell, to     \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                      copy it or customize    \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                      the installation.       \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                      \u001b[2m[default: None]        \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-help\u001b[0m                      \u001b[1;33m                       \u001b[0m  Show this message and   \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                      exit.                   \u001b[2m│\u001b[0m\n",
      "\u001b[2m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\u001b[2m╭─\u001b[0m\u001b[2m Commands \u001b[0m\u001b[2m──────────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "\u001b[2m│\u001b[0m \u001b[1;36mdrop-schema   \u001b[0m\u001b[1;36m \u001b[0m DROP a schema. Useful for cleaning up after a demo.          \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m \u001b[1;36mdrop-stage    \u001b[0m\u001b[1;36m \u001b[0m DROP the stage. Useful when all the data has been            \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m \u001b[1;36m               \u001b[0m successfully loaded.                                         \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m \u001b[1;36mprocess-files \u001b[0m\u001b[1;36m \u001b[0m Upload a file or files into the stage and build the          \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m \u001b[1;36m               \u001b[0m dependent tables.                                            \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m \u001b[1;36mrecreate-stage\u001b[0m\u001b[1;36m \u001b[0m CREATE or REPLACE the stage. Mostly useful while developing  \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m \u001b[1;36m               \u001b[0m this utility.                                                \u001b[2m│\u001b[0m\n",
      "\u001b[2m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python tpcdi.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m                                                                                \u001b[0m\n",
      "\u001b[1m \u001b[0m\u001b[1;33mUsage: \u001b[0m\u001b[1mtpcdi.py process-files [OPTIONS]\u001b[0m\u001b[1m                                       \u001b[0m\u001b[1m \u001b[0m\n",
      "\u001b[1m                                                                                \u001b[0m\n",
      " Upload a file or files into the stage and build the dependent tables.          \n",
      "                                                                                \n",
      "\u001b[2m╭─\u001b[0m\u001b[2m Options \u001b[0m\u001b[2m───────────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "\u001b[2m│\u001b[0m \u001b[31m*\u001b[0m  \u001b[1;36m-\u001b[0m\u001b[1;36m-output\u001b[0m\u001b[1;36m-directory\u001b[0m                        \u001b[1;33mTEXT   \u001b[0m  The output directory   \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       from the TPC-DI        \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       DIGen.jar execution.   \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2m[default: None]       \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2;31m[required]            \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-file\u001b[0m\u001b[1;36m-name\u001b[0m                               \u001b[1;33mTEXT   \u001b[0m  The TPC-DI file name   \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       to upload and process. \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       Pass value 'FINWIRE'   \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       to process all of the  \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       financial wire files.  \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2m[default: all]        \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-stage\u001b[0m                                   \u001b[1;33mTEXT   \u001b[0m  The stage name to      \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       upload to, without     \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       specifying '@'.        \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2m[default: tpcdi]      \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-batch\u001b[0m                                   \u001b[1;33mINTEGER\u001b[0m  The TPC-DI batch       \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       number to process.     \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       Currently only         \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       supports the default   \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       of '1'.                \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2m[default: 1]          \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-overwrite\u001b[0m           \u001b[1;35m-\u001b[0m\u001b[1;35m-no\u001b[0m\u001b[1;35m-overwrite\u001b[0m      \u001b[1;33m       \u001b[0m  Overwrite the file     \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       even if it exists?     \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2m[default:             \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2mno-overwrite]         \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-skip\u001b[0m\u001b[1;36m-upload\u001b[0m         \u001b[1;35m-\u001b[0m\u001b[1;35m-no\u001b[0m\u001b[1;35m-skip-upload\u001b[0m    \u001b[1;33m       \u001b[0m  Skip uploading the     \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       files?                 \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2m[default:             \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2mno-skip-upload]       \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-show\u001b[0m                \u001b[1;35m-\u001b[0m\u001b[1;35m-no\u001b[0m\u001b[1;35m-show\u001b[0m           \u001b[1;33m       \u001b[0m  Show the DataFrame     \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       instead of saving it   \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       as a table? This was   \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       useful during          \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       development.           \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2m[default: no-show]    \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-help\u001b[0m                                    \u001b[1;33m       \u001b[0m  Show this message and  \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       exit.                  \u001b[2m│\u001b[0m\n",
      "\u001b[2m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python tpcdi.py process-files --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File DailyMarket.txt: SKIPPED\n",
      "----------------------------------------------------------------------------------\n",
      "|\"DM_DATE\"   |\"DM_S_SYMB\"      |\"DM_CLOSE\"  |\"DM_HIGH\"  |\"DM_LOW\"  |\"DM_VOL\"     |\n",
      "----------------------------------------------------------------------------------\n",
      "|2015-07-06  |AAAAAAAAAAAAERN  |242.93      |284.42     |185.08    |111904727.0  |\n",
      "|2015-07-06  |AAAAAAAAAAAAEYJ  |445.46      |522.3      |386.48    |78849320.0   |\n",
      "|2015-07-06  |AAAAAAAAAAAAEVC  |910.59      |1148.89    |723.37    |807515829.0  |\n",
      "|2015-07-06  |AAAAAAAAAAAACEZ  |647.07      |756.68     |473.3     |693226268.0  |\n",
      "|2015-07-06  |AAAAAAAAAAAADOY  |385.01      |564.67     |295.63    |34628570.0   |\n",
      "|2015-07-06  |AAAAAAAAAAAADSD  |28.01       |34.59      |23.66     |47032973.0   |\n",
      "|2015-07-06  |AAAAAAAAAAAAELH  |186.85      |249.13     |170.26    |79305649.0   |\n",
      "|2015-07-06  |AAAAAAAAAAAAAXX  |880.03      |990.35     |727.51    |353491380.0  |\n",
      "|2015-07-06  |AAAAAAAAAAAABVO  |911.31      |1143.78    |695.46    |868269480.0  |\n",
      "|2015-07-06  |AAAAAAAAAAAADBL  |23.44       |27.08      |13.28     |441304717.0  |\n",
      "----------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python tpcdi.py process-files --output-directory ~/dev/tpcdi-output --file-name DailyMarket.txt --show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get nothing else from this video, know that there's an easy way to load this dataset into Snowflake.\n",
    "\n",
    "But I also wanted to show some interesting approaches using Snowpark.\n",
    "\n",
    "All of the code samples below are snippets from the CLI with abstractions removed.\n",
    "\n",
    "We start with a `credentials.json` file to store our Snowflake credentials. Something like this:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"account\": \"myaccount\",\n",
    "    \"user\": \"myuser\",\n",
    "    \"password\": \"mypassword\",\n",
    "    \"role\": \"myrole\",\n",
    "    \"warehouse\": \"stewart_dev\",\n",
    "    \"database\": \"tpc_di\",\n",
    "    \"schema\": \"digen\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can make a connection to Snowflake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, json\n",
    "from snowflake.snowpark import Session, DataFrame\n",
    "from snowflake.snowpark.types import *\n",
    "from snowflake.snowpark.functions import *\n",
    "from pathlib import Path\n",
    "\n",
    "# Read the credentials.json file\n",
    "with open(\"credentials.json\") as jsonfile:\n",
    "    credentials_dict = json.load(jsonfile)\n",
    "\n",
    "# build the session\n",
    "session = (\n",
    "    Session\n",
    "    .builder\n",
    "    .configs(credentials_dict)\n",
    "    .create()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the files generated by `DIGen.jar` are pipe-separated files, very similar to CSV files.\n",
    "\n",
    "These are very simple to handle. First let's upload the file to a stage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File DailyMarket.txt: SKIPPED\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "source_path = '/Users/stewartbryson/dev/tpcdi-output/Batch1'\n",
    "stage_path = \"@tpcdi/Batch1\"\n",
    "\n",
    "# Put the file\n",
    "put_result = (\n",
    "    session\n",
    "    .file\n",
    "    .put(\n",
    "        f\"{source_path}/DailyMarket.txt\",\n",
    "        f\"{stage_path}/DailyMarket.txt\",\n",
    "        parallel=4,\n",
    "        auto_compress=True,\n",
    "    )\n",
    ")\n",
    "for result in put_result:\n",
    "    print(f\"File {result.source}: {result.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we'll create a table from that file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------\n",
      "|\"DM_DATE\"   |\"DM_S_SYMB\"      |\"DM_CLOSE\"  |\"DM_HIGH\"  |\"DM_LOW\"  |\"DM_VOL\"     |\n",
      "----------------------------------------------------------------------------------\n",
      "|2016-12-18  |AAAAAAAAAAAABZF  |961.07      |1394.14    |847.64    |709969048.0  |\n",
      "|2016-12-18  |AAAAAAAAAAAABGY  |134.65      |173.1      |106.55    |122085128.0  |\n",
      "|2016-12-18  |AAAAAAAAAAAACFY  |497.2       |741.06     |427.71    |8263059.0    |\n",
      "|2016-12-18  |AAAAAAAAAAAACJW  |697.83      |988.37     |630.96    |576146934.0  |\n",
      "|2016-12-18  |AAAAAAAAAAAAELN  |512.4       |699.93     |508.04    |532344015.0  |\n",
      "|2016-12-18  |AAAAAAAAAAAADQU  |115.56      |146.54     |71.32     |808265496.0  |\n",
      "|2016-12-18  |AAAAAAAAAAAABSG  |38.99       |39.65      |29.36     |696226368.0  |\n",
      "|2016-12-18  |AAAAAAAAAAAAAOO  |640.01      |905.5      |581.14    |828920058.0  |\n",
      "|2016-12-18  |AAAAAAAAAAAACYZ  |396.78      |536.03     |233.16    |713253731.0  |\n",
      "|2016-12-18  |AAAAAAAAAAAABJF  |531.56      |706.06     |504.6     |629992002.0  |\n",
      "----------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the schema\n",
    "schema = StructType([\n",
    "                StructField(\"DM_DATE\", DateType(), False),\n",
    "                StructField(\"DM_S_SYMB\", StringType(), False),\n",
    "                StructField(\"DM_CLOSE\", FloatType(), False),\n",
    "                StructField(\"DM_HIGH\", FloatType(), False),\n",
    "                StructField(\"DM_LOW\", FloatType(), False),\n",
    "                StructField(\"DM_VOL\", FloatType(), False),\n",
    "        ])\n",
    "\n",
    "# create a table from a DataFrame\n",
    "df = (\n",
    "    session\n",
    "    .read\n",
    "    .schema(schema)\n",
    "    .option(\"field_delimiter\", '|')\n",
    "    .csv(f\"{stage_path}/DailyMarket.txt\")\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .save_as_table('daily_market')\n",
    ")\n",
    "\n",
    "# show the table\n",
    "df = (\n",
    "    session \n",
    "    .table('daily_market') \n",
    "    .show()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DIGen.jar` utility generates a series of \"finwire\" files.\n",
    "\n",
    "These files represent market history over time.\n",
    "\n",
    "They are fixed-width, multi-format files.\n",
    "For instance, the following sample has one of each type of record: `FIN`, `SEC`, and `CMP`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20151230-152248FIN201542015100120151230    4880880089.63    2473473307.30        4.82        4.42        0.51     200321223.47  139284472514.02    9402305760.19    512872010    5597926720000001595\n",
      "20151230-152511SECAAAAAAAAAAAAKVDPREF_AACTVDJBJXyQHLBvn EEOGAOvUNgL XwrOxQUBMrgPv                                AMEX  982113436    1903022619730704        1.200000000254\n",
      "20151230-163207CMPWWfcsOHprIDIUsPfRLrcLPlxaQ                                  0000004432ACTVMCA   1873092521088 Vessey Crescent                                                                                                                                           M5D 1Z1     Winnipeg                 AL                  United States of AmericaMoreno                                        rlRIDCNz dVGrEzomCXIvZVZzFzxCzbGYIEbAXJMJlsYUQEV"
     ]
    }
   ],
   "source": [
    "!cat devrel/multi-record.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by uploading all the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File FINWIRE2001Q3: SKIPPED\n",
      "File FINWIRE2001Q4: SKIPPED\n",
      "File FINWIRE1997Q4: SKIPPED\n",
      "File FINWIRE1970Q3: SKIPPED\n",
      "File FINWIRE1997Q3: SKIPPED\n",
      "File FINWIRE1970Q4: SKIPPED\n",
      "File FINWIRE1999Q2: SKIPPED\n",
      "File FINWIRE1991Q1: SKIPPED\n",
      "File FINWIRE2005Q2: SKIPPED\n",
      "File FINWIRE1976Q1: SKIPPED\n",
      "File FINWIRE1993Q2: SKIPPED\n",
      "File FINWIRE1974Q2: SKIPPED\n",
      "File FINWIRE2007Q1: SKIPPED\n",
      "File FINWIRE1997Q2: SKIPPED\n",
      "File FINWIRE1978Q1: SKIPPED\n",
      "File FINWIRE1970Q2: SKIPPED\n",
      "File FINWIRE2003Q1: SKIPPED\n",
      "File FINWIRE1995Q1: SKIPPED\n",
      "File FINWIRE2009Q1: SKIPPED\n",
      "File FINWIRE2001Q2: SKIPPED\n",
      "File FINWIRE1972Q1: SKIPPED\n",
      "File FINWIRE1974Q3: SKIPPED\n",
      "File FINWIRE1993Q4: SKIPPED\n",
      "File FINWIRE1974Q4: SKIPPED\n",
      "File FINWIRE1993Q3: SKIPPED\n",
      "File FINWIRE1999Q4: SKIPPED\n",
      "File FINWIRE2005Q3: SKIPPED\n",
      "File FINWIRE2005Q4: SKIPPED\n",
      "File FINWIRE1999Q3: SKIPPED\n",
      "File FINWIRE1987Q2: SKIPPED\n",
      "File FINWIRE1968Q1: SKIPPED\n",
      "File FINWIRE2013Q1: SKIPPED\n",
      "File FINWIRE1985Q1: SKIPPED\n",
      "File FINWIRE2011Q2: SKIPPED\n",
      "File FINWIRE1983Q4: SKIPPED\n",
      "File FINWIRE1983Q3: SKIPPED\n",
      "File FINWIRE1989Q4: SKIPPED\n",
      "File FINWIRE2015Q3: SKIPPED\n",
      "File FINWIRE2015Q4: SKIPPED\n",
      "File FINWIRE1989Q3: SKIPPED\n",
      "File FINWIRE2011Q3: SKIPPED\n",
      "File FINWIRE2011Q4: SKIPPED\n",
      "File FINWIRE1987Q4: SKIPPED\n",
      "File FINWIRE1987Q3: SKIPPED\n",
      "File FINWIRE1989Q2: SKIPPED\n",
      "File FINWIRE1981Q1: SKIPPED\n",
      "File FINWIRE2015Q2: SKIPPED\n",
      "File FINWIRE1983Q2: SKIPPED\n",
      "File FINWIRE2017Q1: SKIPPED\n",
      "File FINWIRE1992Q1: SKIPPED\n",
      "File FINWIRE1975Q1: SKIPPED\n",
      "File FINWIRE2006Q2: SKIPPED\n",
      "File FINWIRE1990Q2: SKIPPED\n",
      "File FINWIRE1998Q1: SKIPPED\n",
      "File FINWIRE2004Q1: SKIPPED\n",
      "File FINWIRE1977Q2: SKIPPED\n",
      "File FINWIRE2002Q3: SKIPPED\n",
      "File FINWIRE1979Q3: SKIPPED\n",
      "File FINWIRE2002Q4: SKIPPED\n",
      "File FINWIRE1979Q4: SKIPPED\n",
      "File FINWIRE1973Q3: SKIPPED\n",
      "File FINWIRE2008Q3: SKIPPED\n",
      "File FINWIRE1994Q4: SKIPPED\n",
      "File FINWIRE1973Q4: SKIPPED\n",
      "File FINWIRE1994Q3: SKIPPED\n",
      "File FINWIRE2008Q4: SKIPPED\n",
      "File FINWIRE1990Q4: SKIPPED\n",
      "File FINWIRE1977Q3: SKIPPED\n",
      "File FINWIRE1990Q3: SKIPPED\n",
      "File FINWIRE1977Q4: SKIPPED\n",
      "File FINWIRE2006Q3: SKIPPED\n",
      "File FINWIRE2006Q4: SKIPPED\n",
      "File FINWIRE1994Q2: SKIPPED\n",
      "File FINWIRE2000Q1: SKIPPED\n",
      "File FINWIRE1973Q2: SKIPPED\n",
      "File FINWIRE2008Q2: SKIPPED\n",
      "File FINWIRE1996Q1: SKIPPED\n",
      "File FINWIRE1971Q1: SKIPPED\n",
      "File FINWIRE2002Q2: SKIPPED\n",
      "File FINWIRE1979Q2: SKIPPED\n",
      "File FINWIRE1980Q4: SKIPPED\n",
      "File FINWIRE1967Q3: SKIPPED\n",
      "File FINWIRE1980Q3: SKIPPED\n",
      "File FINWIRE1967Q4: SKIPPED\n",
      "File FINWIRE2016Q3: SKIPPED\n",
      "File FINWIRE2016Q4: SKIPPED\n",
      "File FINWIRE1984Q2: SKIPPED\n",
      "File FINWIRE2010Q1: SKIPPED\n",
      "File FINWIRE1986Q1: SKIPPED\n",
      "File FINWIRE2012Q2: SKIPPED\n",
      "File FINWIRE1969Q2: SKIPPED\n",
      "File FINWIRE1982Q1: SKIPPED\n",
      "File FINWIRE2016Q2: SKIPPED\n",
      "File FINWIRE1980Q2: SKIPPED\n",
      "File FINWIRE1988Q1: SKIPPED\n",
      "File FINWIRE2014Q1: SKIPPED\n",
      "File FINWIRE1967Q2: SKIPPED\n",
      "File FINWIRE2012Q3: SKIPPED\n",
      "File FINWIRE1969Q3: SKIPPED\n",
      "File FINWIRE2012Q4: SKIPPED\n",
      "File FINWIRE1969Q4: SKIPPED\n",
      "File FINWIRE1984Q4: SKIPPED\n",
      "File FINWIRE1984Q3: SKIPPED\n",
      "File FINWIRE2005Q1: SKIPPED\n",
      "File FINWIRE1976Q2: SKIPPED\n",
      "File FINWIRE1999Q1: SKIPPED\n",
      "File FINWIRE1991Q2: SKIPPED\n",
      "File FINWIRE1974Q1: SKIPPED\n",
      "File FINWIRE2007Q2: SKIPPED\n",
      "File FINWIRE1993Q1: SKIPPED\n",
      "File FINWIRE2009Q4: SKIPPED\n",
      "File FINWIRE1995Q3: SKIPPED\n",
      "File FINWIRE1972Q4: SKIPPED\n",
      "File FINWIRE1995Q4: SKIPPED\n",
      "File FINWIRE2009Q3: SKIPPED\n",
      "File FINWIRE1972Q3: SKIPPED\n",
      "File FINWIRE1978Q4: SKIPPED\n",
      "File FINWIRE2003Q4: SKIPPED\n",
      "File FINWIRE1978Q3: SKIPPED\n",
      "File FINWIRE2003Q3: SKIPPED\n",
      "File FINWIRE2007Q4: SKIPPED\n",
      "File FINWIRE2007Q3: SKIPPED\n",
      "File FINWIRE1976Q4: SKIPPED\n",
      "File FINWIRE1991Q3: SKIPPED\n",
      "File FINWIRE1976Q3: SKIPPED\n",
      "File FINWIRE1991Q4: SKIPPED\n",
      "File FINWIRE1978Q2: SKIPPED\n",
      "File FINWIRE1970Q1: SKIPPED\n",
      "File FINWIRE2003Q2: SKIPPED\n",
      "File FINWIRE1997Q1: SKIPPED\n",
      "File FINWIRE2009Q2: SKIPPED\n",
      "File FINWIRE2001Q1: SKIPPED\n",
      "File FINWIRE1972Q2: SKIPPED\n",
      "File FINWIRE1995Q2: SKIPPED\n",
      "File FINWIRE2017Q3: SKIPPED\n",
      "File FINWIRE1981Q3: SKIPPED\n",
      "File FINWIRE1981Q4: SKIPPED\n",
      "File FINWIRE1968Q2: SKIPPED\n",
      "File FINWIRE2013Q2: SKIPPED\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/stewartbryson/Source/dbt-tpcdi/demo.ipynb Cell 22\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/stewartbryson/Source/dbt-tpcdi/demo.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m pathlist \u001b[39m=\u001b[39m (\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/stewartbryson/Source/dbt-tpcdi/demo.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     Path(source_path)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/stewartbryson/Source/dbt-tpcdi/demo.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m.\u001b[39mglob(\u001b[39m\"\u001b[39m\u001b[39mFINWIRE??????\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/stewartbryson/Source/dbt-tpcdi/demo.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/stewartbryson/Source/dbt-tpcdi/demo.ipynb#X24sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m pathlist:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/stewartbryson/Source/dbt-tpcdi/demo.ipynb#X24sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m# put the file(s) in the stage\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/stewartbryson/Source/dbt-tpcdi/demo.ipynb#X24sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     put_result \u001b[39m=\u001b[39m (\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/stewartbryson/Source/dbt-tpcdi/demo.ipynb#X24sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         session \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/stewartbryson/Source/dbt-tpcdi/demo.ipynb#X24sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         \u001b[39m.\u001b[39;49mfile\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/stewartbryson/Source/dbt-tpcdi/demo.ipynb#X24sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         \u001b[39m.\u001b[39;49mput(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/stewartbryson/Source/dbt-tpcdi/demo.ipynb#X24sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m             \u001b[39mstr\u001b[39;49m(file), \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/stewartbryson/Source/dbt-tpcdi/demo.ipynb#X24sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m             stage_path, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/stewartbryson/Source/dbt-tpcdi/demo.ipynb#X24sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m             parallel\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/stewartbryson/Source/dbt-tpcdi/demo.ipynb#X24sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m             auto_compress\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/stewartbryson/Source/dbt-tpcdi/demo.ipynb#X24sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m         )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/stewartbryson/Source/dbt-tpcdi/demo.ipynb#X24sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/stewartbryson/Source/dbt-tpcdi/demo.ipynb#X24sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39mfor\u001b[39;00m result \u001b[39min\u001b[39;00m put_result:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/stewartbryson/Source/dbt-tpcdi/demo.ipynb#X24sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFile \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m.\u001b[39msource\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m.\u001b[39mstatus\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tpcdi/lib/python3.8/site-packages/snowflake/snowpark/file_operation.py:137\u001b[0m, in \u001b[0;36mFileOperation.put\u001b[0;34m(self, local_file_name, stage_location, parallel, auto_compress, source_compression, overwrite, statement_params)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m     plan \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_session\u001b[39m.\u001b[39m_plan_builder\u001b[39m.\u001b[39mfile_operation_plan(\n\u001b[1;32m    132\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mput\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    133\u001b[0m         normalize_local_file(local_file_name),\n\u001b[1;32m    134\u001b[0m         normalize_remote_file_or_dir(stage_location),\n\u001b[1;32m    135\u001b[0m         options,\n\u001b[1;32m    136\u001b[0m     )\n\u001b[0;32m--> 137\u001b[0m     put_result \u001b[39m=\u001b[39m snowflake\u001b[39m.\u001b[39;49msnowpark\u001b[39m.\u001b[39;49mdataframe\u001b[39m.\u001b[39;49mDataFrame(\n\u001b[1;32m    138\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session, plan\n\u001b[1;32m    139\u001b[0m     )\u001b[39m.\u001b[39;49m_internal_collect_with_tag(statement_params\u001b[39m=\u001b[39;49mstatement_params)\n\u001b[1;32m    140\u001b[0m \u001b[39mreturn\u001b[39;00m [PutResult(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfile_result\u001b[39m.\u001b[39masDict()) \u001b[39mfor\u001b[39;00m file_result \u001b[39min\u001b[39;00m put_result]\n",
      "File \u001b[0;32m~/anaconda3/envs/tpcdi/lib/python3.8/site-packages/snowflake/snowpark/_internal/telemetry.py:139\u001b[0m, in \u001b[0;36mdf_collect_api_telemetry.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    138\u001b[0m     \u001b[39mwith\u001b[39;00m args[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_session\u001b[39m.\u001b[39mquery_history() \u001b[39mas\u001b[39;00m query_history:\n\u001b[0;32m--> 139\u001b[0m         result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    140\u001b[0m     plan \u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_select_statement \u001b[39mor\u001b[39;00m args[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_plan\n\u001b[1;32m    141\u001b[0m     api_calls \u001b[39m=\u001b[39m [\n\u001b[1;32m    142\u001b[0m         \u001b[39m*\u001b[39mplan\u001b[39m.\u001b[39mapi_calls,\n\u001b[1;32m    143\u001b[0m         {TelemetryField\u001b[39m.\u001b[39mNAME\u001b[39m.\u001b[39mvalue: \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDataFrame.\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    144\u001b[0m     ]\n",
      "File \u001b[0;32m~/anaconda3/envs/tpcdi/lib/python3.8/site-packages/snowflake/snowpark/dataframe.py:634\u001b[0m, in \u001b[0;36mDataFrame._internal_collect_with_tag_no_telemetry\u001b[0;34m(self, statement_params, block, data_type, log_on_exception, case_sensitive)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_internal_collect_with_tag_no_telemetry\u001b[39m(\n\u001b[1;32m    623\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    624\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    632\u001b[0m     \u001b[39m# we should always call this method instead of collect(), to make sure the\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39m# query tag is set properly.\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session\u001b[39m.\u001b[39;49m_conn\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    635\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_plan,\n\u001b[1;32m    636\u001b[0m         block\u001b[39m=\u001b[39;49mblock,\n\u001b[1;32m    637\u001b[0m         data_type\u001b[39m=\u001b[39;49mdata_type,\n\u001b[1;32m    638\u001b[0m         _statement_params\u001b[39m=\u001b[39;49mcreate_or_update_statement_params_with_query_tag(\n\u001b[1;32m    639\u001b[0m             statement_params \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_statement_params,\n\u001b[1;32m    640\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session\u001b[39m.\u001b[39;49mquery_tag,\n\u001b[1;32m    641\u001b[0m             SKIP_LEVELS_THREE,\n\u001b[1;32m    642\u001b[0m         ),\n\u001b[1;32m    643\u001b[0m         log_on_exception\u001b[39m=\u001b[39;49mlog_on_exception,\n\u001b[1;32m    644\u001b[0m         case_sensitive\u001b[39m=\u001b[39;49mcase_sensitive,\n\u001b[1;32m    645\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/tpcdi/lib/python3.8/site-packages/snowflake/snowpark/_internal/server_connection.py:442\u001b[0m, in \u001b[0;36mServerConnection.execute\u001b[0;34m(self, plan, to_pandas, to_iter, block, data_type, log_on_exception, case_sensitive, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mif\u001b[39;00m is_in_stored_procedure() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m block:  \u001b[39m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    439\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    440\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAsync query is not supported in stored procedure yet\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    441\u001b[0m     )\n\u001b[0;32m--> 442\u001b[0m result_set, result_meta \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_result_set(\n\u001b[1;32m    443\u001b[0m     plan,\n\u001b[1;32m    444\u001b[0m     to_pandas,\n\u001b[1;32m    445\u001b[0m     to_iter,\n\u001b[1;32m    446\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    447\u001b[0m     block\u001b[39m=\u001b[39;49mblock,\n\u001b[1;32m    448\u001b[0m     data_type\u001b[39m=\u001b[39;49mdata_type,\n\u001b[1;32m    449\u001b[0m     log_on_exception\u001b[39m=\u001b[39;49mlog_on_exception,\n\u001b[1;32m    450\u001b[0m     case_sensitive\u001b[39m=\u001b[39;49mcase_sensitive,\n\u001b[1;32m    451\u001b[0m )\n\u001b[1;32m    452\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m block:\n\u001b[1;32m    453\u001b[0m     \u001b[39mreturn\u001b[39;00m result_set\n",
      "File \u001b[0;32m~/anaconda3/envs/tpcdi/lib/python3.8/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py:110\u001b[0m, in \u001b[0;36mSnowflakePlan.Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    109\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    111\u001b[0m     \u001b[39mexcept\u001b[39;00m snowflake\u001b[39m.\u001b[39mconnector\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mProgrammingError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    112\u001b[0m         query \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tpcdi/lib/python3.8/site-packages/snowflake/snowpark/_internal/server_connection.py:550\u001b[0m, in \u001b[0;36mServerConnection.get_result_set\u001b[0;34m(self, plan, to_pandas, to_iter, block, data_type, log_on_exception, case_sensitive, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[39mfor\u001b[39;00m holder, id_ \u001b[39min\u001b[39;00m placeholders\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    549\u001b[0m     final_query \u001b[39m=\u001b[39m final_query\u001b[39m.\u001b[39mreplace(holder, id_)\n\u001b[0;32m--> 550\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_query(\n\u001b[1;32m    551\u001b[0m     final_query,\n\u001b[1;32m    552\u001b[0m     to_pandas,\n\u001b[1;32m    553\u001b[0m     to_iter \u001b[39mand\u001b[39;49;00m (i \u001b[39m==\u001b[39;49m \u001b[39mlen\u001b[39;49m(plan\u001b[39m.\u001b[39;49mqueries) \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m),\n\u001b[1;32m    554\u001b[0m     is_ddl_on_temp_object\u001b[39m=\u001b[39;49mquery\u001b[39m.\u001b[39;49mis_ddl_on_temp_object,\n\u001b[1;32m    555\u001b[0m     block\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m is_last,\n\u001b[1;32m    556\u001b[0m     data_type\u001b[39m=\u001b[39;49mdata_type,\n\u001b[1;32m    557\u001b[0m     async_job_plan\u001b[39m=\u001b[39;49mplan,\n\u001b[1;32m    558\u001b[0m     log_on_exception\u001b[39m=\u001b[39;49mlog_on_exception,\n\u001b[1;32m    559\u001b[0m     case_sensitive\u001b[39m=\u001b[39;49mcase_sensitive,\n\u001b[1;32m    560\u001b[0m     params\u001b[39m=\u001b[39;49mquery\u001b[39m.\u001b[39;49mparams,\n\u001b[1;32m    561\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    562\u001b[0m )\n\u001b[1;32m    563\u001b[0m placeholders[query\u001b[39m.\u001b[39mquery_id_place_holder] \u001b[39m=\u001b[39m (\n\u001b[1;32m    564\u001b[0m     result[\u001b[39m\"\u001b[39m\u001b[39msfqid\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_last \u001b[39melse\u001b[39;00m result\u001b[39m.\u001b[39mquery_id\n\u001b[1;32m    565\u001b[0m )\n\u001b[1;32m    566\u001b[0m result_meta \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cursor\u001b[39m.\u001b[39mdescription\n",
      "File \u001b[0;32m~/anaconda3/envs/tpcdi/lib/python3.8/site-packages/snowflake/snowpark/_internal/server_connection.py:96\u001b[0m, in \u001b[0;36mServerConnection._Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[39mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[39m.\u001b[39mSERVER_SESSION_HAS_BEEN_CLOSED()\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m ReauthenticationRequest \u001b[39mas\u001b[39;00m ex:\n\u001b[1;32m     98\u001b[0m     \u001b[39mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[39m.\u001b[39mSERVER_SESSION_EXPIRED(\n\u001b[1;32m     99\u001b[0m         ex\u001b[39m.\u001b[39mcause\n\u001b[1;32m    100\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/tpcdi/lib/python3.8/site-packages/snowflake/snowpark/_internal/server_connection.py:346\u001b[0m, in \u001b[0;36mServerConnection.run_query\u001b[0;34m(self, query, to_pandas, to_iter, is_ddl_on_temp_object, block, data_type, async_job_plan, log_on_exception, case_sensitive, params, **kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39m_statement_params\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mSNOWPARK_SKIP_TXN_COMMIT_IN_DDL\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[0;32m--> 346\u001b[0m     results_cursor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cursor\u001b[39m.\u001b[39;49mexecute(query, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    347\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify_query_listeners(\n\u001b[1;32m    348\u001b[0m         QueryRecord(results_cursor\u001b[39m.\u001b[39msfqid, results_cursor\u001b[39m.\u001b[39mquery)\n\u001b[1;32m    349\u001b[0m     )\n\u001b[1;32m    350\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExecute query [queryID: \u001b[39m\u001b[39m{\u001b[39;00mresults_cursor\u001b[39m.\u001b[39msfqid\u001b[39m}\u001b[39;00m\u001b[39m] \u001b[39m\u001b[39m{\u001b[39;00mquery\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tpcdi/lib/python3.8/site-packages/snowflake/connector/cursor.py:801\u001b[0m, in \u001b[0;36mSnowflakeCursor.execute\u001b[0;34m(self, command, params, _bind_stage, timeout, _exec_async, _no_retry, _do_reset, _put_callback, _put_azure_callback, _put_callback_output_stream, _get_callback, _get_azure_callback, _get_callback_output_stream, _show_progress_bar, _statement_params, _is_internal, _describe_only, _no_results, _is_put_get, _raise_put_get_error, _force_put_overwrite, _skip_upload_on_content_match, file_stream, num_statements)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[39mif\u001b[39;00m logger\u001b[39m.\u001b[39mgetEffectiveLevel() \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mINFO:\n\u001b[1;32m    800\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mquery: [\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_query_for_log(query))\n\u001b[0;32m--> 801\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_helper(query, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    802\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sfqid \u001b[39m=\u001b[39m (\n\u001b[1;32m    803\u001b[0m     ret[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mqueryId\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    804\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m ret \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mqueryId\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m ret[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    805\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    806\u001b[0m )\n\u001b[1;32m    807\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msfqid: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msfqid\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tpcdi/lib/python3.8/site-packages/snowflake/connector/cursor.py:521\u001b[0m, in \u001b[0;36mSnowflakeCursor._execute_helper\u001b[0;34m(self, query, timeout, statement_params, binding_params, binding_stage, is_internal, describe_only, _no_results, _is_put_get, _no_retry)\u001b[0m\n\u001b[1;32m    519\u001b[0m ret: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m: {}}\n\u001b[1;32m    520\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 521\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_connection\u001b[39m.\u001b[39;49mcmd_query(\n\u001b[1;32m    522\u001b[0m         query,\n\u001b[1;32m    523\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sequence_counter,\n\u001b[1;32m    524\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request_id,\n\u001b[1;32m    525\u001b[0m         binding_params\u001b[39m=\u001b[39;49mbinding_params,\n\u001b[1;32m    526\u001b[0m         binding_stage\u001b[39m=\u001b[39;49mbinding_stage,\n\u001b[1;32m    527\u001b[0m         is_file_transfer\u001b[39m=\u001b[39;49m\u001b[39mbool\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_is_file_transfer),\n\u001b[1;32m    528\u001b[0m         statement_params\u001b[39m=\u001b[39;49mstatement_params,\n\u001b[1;32m    529\u001b[0m         is_internal\u001b[39m=\u001b[39;49mis_internal,\n\u001b[1;32m    530\u001b[0m         describe_only\u001b[39m=\u001b[39;49mdescribe_only,\n\u001b[1;32m    531\u001b[0m         _no_results\u001b[39m=\u001b[39;49m_no_results,\n\u001b[1;32m    532\u001b[0m         _no_retry\u001b[39m=\u001b[39;49m_no_retry,\n\u001b[1;32m    533\u001b[0m     )\n\u001b[1;32m    534\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    535\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tpcdi/lib/python3.8/site-packages/snowflake/connector/connection.py:1067\u001b[0m, in \u001b[0;36mSnowflakeConnection.cmd_query\u001b[0;34m(self, sql, sequence_counter, request_id, binding_params, binding_stage, is_file_transfer, statement_params, is_internal, describe_only, _no_results, _update_current_object, _no_retry)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\n\u001b[1;32m   1059\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msql=[\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m], sequence_id=[\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m], is_file_transfer=[\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1060\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_query_for_log(data[\u001b[39m\"\u001b[39m\u001b[39msqlText\u001b[39m\u001b[39m\"\u001b[39m]),\n\u001b[1;32m   1061\u001b[0m         data[\u001b[39m\"\u001b[39m\u001b[39msequenceId\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   1062\u001b[0m         is_file_transfer,\n\u001b[1;32m   1063\u001b[0m     )\n\u001b[1;32m   1065\u001b[0m url_parameters \u001b[39m=\u001b[39m {REQUEST_ID: request_id}\n\u001b[0;32m-> 1067\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrest\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m   1068\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39m/queries/v1/query-request?\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m urlencode(url_parameters),\n\u001b[1;32m   1069\u001b[0m     data,\n\u001b[1;32m   1070\u001b[0m     client\u001b[39m=\u001b[39;49mclient,\n\u001b[1;32m   1071\u001b[0m     _no_results\u001b[39m=\u001b[39;49m_no_results,\n\u001b[1;32m   1072\u001b[0m     _include_retry_params\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1073\u001b[0m     _no_retry\u001b[39m=\u001b[39;49m_no_retry,\n\u001b[1;32m   1074\u001b[0m )\n\u001b[1;32m   1076\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     ret \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m: {}}\n",
      "File \u001b[0;32m~/anaconda3/envs/tpcdi/lib/python3.8/site-packages/snowflake/connector/network.py:477\u001b[0m, in \u001b[0;36mSnowflakeRestful.request\u001b[0;34m(self, url, body, method, client, _no_results, timeout, _include_retry_params, _no_retry)\u001b[0m\n\u001b[1;32m    475\u001b[0m     headers[HTTP_HEADER_SERVICE_NAME] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_connection\u001b[39m.\u001b[39mservice_name\n\u001b[1;32m    476\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 477\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post_request(\n\u001b[1;32m    478\u001b[0m         url,\n\u001b[1;32m    479\u001b[0m         headers,\n\u001b[1;32m    480\u001b[0m         json\u001b[39m.\u001b[39;49mdumps(body),\n\u001b[1;32m    481\u001b[0m         token\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtoken,\n\u001b[1;32m    482\u001b[0m         _no_results\u001b[39m=\u001b[39;49m_no_results,\n\u001b[1;32m    483\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    484\u001b[0m         _include_retry_params\u001b[39m=\u001b[39;49m_include_retry_params,\n\u001b[1;32m    485\u001b[0m         no_retry\u001b[39m=\u001b[39;49m_no_retry,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[1;32m    487\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_request(url, headers, token\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoken, timeout\u001b[39m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/anaconda3/envs/tpcdi/lib/python3.8/site-packages/snowflake/connector/network.py:716\u001b[0m, in \u001b[0;36mSnowflakeRestful._post_request\u001b[0;34m(self, url, headers, body, token, timeout, _no_results, no_retry, socket_timeout, _include_retry_params)\u001b[0m\n\u001b[1;32m    713\u001b[0m     ret \u001b[39m=\u001b[39m probe_connection(full_url)\n\u001b[1;32m    714\u001b[0m     pprint(ret)\n\u001b[0;32m--> 716\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfetch(\n\u001b[1;32m    717\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    718\u001b[0m     full_url,\n\u001b[1;32m    719\u001b[0m     headers,\n\u001b[1;32m    720\u001b[0m     data\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    721\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    722\u001b[0m     token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m    723\u001b[0m     no_retry\u001b[39m=\u001b[39;49mno_retry,\n\u001b[1;32m    724\u001b[0m     socket_timeout\u001b[39m=\u001b[39;49msocket_timeout,\n\u001b[1;32m    725\u001b[0m     _include_retry_params\u001b[39m=\u001b[39;49m_include_retry_params,\n\u001b[1;32m    726\u001b[0m )\n\u001b[1;32m    727\u001b[0m logger\u001b[39m.\u001b[39mdebug(\n\u001b[1;32m    728\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mret[code] = \u001b[39m\u001b[39m{code}\u001b[39;00m\u001b[39m, after post request\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    729\u001b[0m         code\u001b[39m=\u001b[39m(ret\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcode\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mN/A\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    730\u001b[0m     )\n\u001b[1;32m    731\u001b[0m )\n\u001b[1;32m    733\u001b[0m \u001b[39mif\u001b[39;00m ret\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcode\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m==\u001b[39m SESSION_EXPIRED_GS_CODE:\n",
      "File \u001b[0;32m~/anaconda3/envs/tpcdi/lib/python3.8/site-packages/snowflake/connector/network.py:814\u001b[0m, in \u001b[0;36mSnowflakeRestful.fetch\u001b[0;34m(self, method, full_url, headers, data, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    812\u001b[0m retry_ctx \u001b[39m=\u001b[39m RetryCtx(timeout, include_retry_params)\n\u001b[1;32m    813\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 814\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request_exec_wrapper(\n\u001b[1;32m    815\u001b[0m         session, method, full_url, headers, data, retry_ctx, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    816\u001b[0m     )\n\u001b[1;32m    817\u001b[0m     \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    818\u001b[0m         \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/anaconda3/envs/tpcdi/lib/python3.8/site-packages/snowflake/connector/network.py:857\u001b[0m, in \u001b[0;36mSnowflakeRestful._request_exec_wrapper\u001b[0;34m(self, session, method, full_url, headers, data, retry_ctx, no_retry, token, **kwargs)\u001b[0m\n\u001b[1;32m    855\u001b[0m full_url \u001b[39m=\u001b[39m SnowflakeRestful\u001b[39m.\u001b[39madd_request_guid(full_url)\n\u001b[1;32m    856\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 857\u001b[0m     return_object \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request_exec(\n\u001b[1;32m    858\u001b[0m         session\u001b[39m=\u001b[39;49msession,\n\u001b[1;32m    859\u001b[0m         method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    860\u001b[0m         full_url\u001b[39m=\u001b[39;49mfull_url,\n\u001b[1;32m    861\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    862\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    863\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m    864\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    865\u001b[0m     )\n\u001b[1;32m    866\u001b[0m     \u001b[39mif\u001b[39;00m return_object \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[39mreturn\u001b[39;00m return_object\n",
      "File \u001b[0;32m~/anaconda3/envs/tpcdi/lib/python3.8/site-packages/snowflake/connector/network.py:1033\u001b[0m, in \u001b[0;36mSnowflakeRestful._request_exec\u001b[0;34m(self, session, method, full_url, headers, data, token, catch_okta_unauthorized_error, is_raw_text, is_raw_binary, binary_data_handler, socket_timeout)\u001b[0m\n\u001b[1;32m   1029\u001b[0m download_start_time \u001b[39m=\u001b[39m get_time_millis()\n\u001b[1;32m   1030\u001b[0m \u001b[39m# socket timeout is constant. You should be able to receive\u001b[39;00m\n\u001b[1;32m   1031\u001b[0m \u001b[39m# the response within the time. If not, ConnectReadTimeout or\u001b[39;00m\n\u001b[1;32m   1032\u001b[0m \u001b[39m# ReadTimeout is raised.\u001b[39;00m\n\u001b[0;32m-> 1033\u001b[0m raw_ret \u001b[39m=\u001b[39m session\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m   1034\u001b[0m     method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m   1035\u001b[0m     url\u001b[39m=\u001b[39;49mfull_url,\n\u001b[1;32m   1036\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m   1037\u001b[0m     data\u001b[39m=\u001b[39;49minput_data,\n\u001b[1;32m   1038\u001b[0m     timeout\u001b[39m=\u001b[39;49msocket_timeout,\n\u001b[1;32m   1039\u001b[0m     verify\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1040\u001b[0m     stream\u001b[39m=\u001b[39;49mis_raw_binary,\n\u001b[1;32m   1041\u001b[0m     auth\u001b[39m=\u001b[39;49mSnowflakeAuth(token),\n\u001b[1;32m   1042\u001b[0m )\n\u001b[1;32m   1043\u001b[0m download_end_time \u001b[39m=\u001b[39m get_time_millis()\n\u001b[1;32m   1045\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tpcdi/lib/python3.8/site-packages/snowflake/connector/vendored/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/envs/tpcdi/lib/python3.8/site-packages/snowflake/connector/vendored/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/anaconda3/envs/tpcdi/lib/python3.8/site-packages/snowflake/connector/vendored/requests/adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 489\u001b[0m         resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    490\u001b[0m             method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    491\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    492\u001b[0m             body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    493\u001b[0m             headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    494\u001b[0m             redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m             assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    496\u001b[0m             preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    497\u001b[0m             decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    498\u001b[0m             retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    499\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    500\u001b[0m         )\n\u001b[1;32m    502\u001b[0m     \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39mproxy_pool\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/tpcdi/lib/python3.8/site-packages/snowflake/connector/vendored/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tpcdi/lib/python3.8/site-packages/snowflake/connector/vendored/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/tpcdi/lib/python3.8/site-packages/snowflake/connector/vendored/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    445\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tpcdi/lib/python3.8/http/client.py:1348\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1347\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1349\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1350\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/tpcdi/lib/python3.8/http/client.py:316\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    317\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    318\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tpcdi/lib/python3.8/http/client.py:277\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 277\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    278\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    279\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tpcdi/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    670\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tpcdi/lib/python3.8/site-packages/snowflake/connector/vendored/urllib3/contrib/pyopenssl.py:323\u001b[0m, in \u001b[0;36mWrappedSocket.recv_into\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[39mexcept\u001b[39;00m OpenSSL\u001b[39m.\u001b[39mSSL\u001b[39m.\u001b[39mWantReadError:\n\u001b[0;32m--> 323\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m util\u001b[39m.\u001b[39;49mwait_for_read(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msocket, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msocket\u001b[39m.\u001b[39;49mgettimeout()):\n\u001b[1;32m    324\u001b[0m         \u001b[39mraise\u001b[39;00m timeout(\u001b[39m\"\u001b[39m\u001b[39mThe read operation timed out\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    325\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tpcdi/lib/python3.8/site-packages/snowflake/connector/vendored/urllib3/util/wait.py:145\u001b[0m, in \u001b[0;36mwait_for_read\u001b[0;34m(sock, timeout)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait_for_read\u001b[39m(sock, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    142\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Waits for reading to be available on a given socket.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39m    Returns True if the socket is readable, or False if the timeout expired.\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m     \u001b[39mreturn\u001b[39;00m wait_for_socket(sock, read\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, timeout\u001b[39m=\u001b[39;49mtimeout)\n",
      "File \u001b[0;32m~/anaconda3/envs/tpcdi/lib/python3.8/site-packages/snowflake/connector/vendored/urllib3/util/wait.py:106\u001b[0m, in \u001b[0;36mpoll_wait_for_socket\u001b[0;34m(sock, read, write, timeout)\u001b[0m\n\u001b[1;32m    103\u001b[0m         t \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[1;32m    104\u001b[0m     \u001b[39mreturn\u001b[39;00m poll_obj\u001b[39m.\u001b[39mpoll(t)\n\u001b[0;32m--> 106\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(_retry_on_intr(do_poll, timeout))\n",
      "File \u001b[0;32m~/anaconda3/envs/tpcdi/lib/python3.8/site-packages/snowflake/connector/vendored/urllib3/util/wait.py:43\u001b[0m, in \u001b[0;36m_retry_on_intr\u001b[0;34m(fn, timeout)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_retry_on_intr\u001b[39m(fn, timeout):\n\u001b[0;32m---> 43\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(timeout)\n",
      "File \u001b[0;32m~/anaconda3/envs/tpcdi/lib/python3.8/site-packages/snowflake/connector/vendored/urllib3/util/wait.py:104\u001b[0m, in \u001b[0;36mpoll_wait_for_socket.<locals>.do_poll\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mif\u001b[39;00m t \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m     t \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[0;32m--> 104\u001b[0m \u001b[39mreturn\u001b[39;00m poll_obj\u001b[39m.\u001b[39;49mpoll(t)\n",
      "File \u001b[0;32m~/anaconda3/envs/tpcdi/lib/python3.8/site-packages/snowflake/connector/cursor.py:510\u001b[0m, in \u001b[0;36mSnowflakeCursor._execute_helper.<locals>.interrupt_handler\u001b[0;34m(*_)\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[1;32m    508\u001b[0m             \u001b[39m# ignore failures\u001b[39;00m\n\u001b[1;32m    509\u001b[0m             \u001b[39mpass\u001b[39;00m\n\u001b[0;32m--> 510\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "stage_path = \"@tpcdi/Batch1/FINWIRE\"\n",
    "\n",
    "# glob the files\n",
    "pathlist = (\n",
    "    Path(source_path)\n",
    "    .glob(\"FINWIRE??????\")\n",
    ")\n",
    "\n",
    "for file in pathlist:\n",
    "    # put the file(s) in the stage\n",
    "    put_result = (\n",
    "        session \n",
    "        .file\n",
    "        .put(\n",
    "            str(file), \n",
    "            stage_path, \n",
    "            parallel=4, \n",
    "            auto_compress=True\n",
    "        )\n",
    "    )\n",
    "    for result in put_result:\n",
    "        print(f\"File {result.source}: {result.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CMP, SEC, and FIN records all have two fields in common, so we want to create a generic DataFrame that contains the shared logic and we’ll save that DataFrame as a Snowflake temporary table called FINWIRE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "|\"LINE\"                                              |\"PTS\"                |\"REC_TYPE\"  |\n",
      "-----------------------------------------------------------------------------------------\n",
      "|19670401-065923FIN196721967040119670401    9288...  |1967-04-01 06:59:23  |FIN         |\n",
      "|19670401-161220FIN196721967040119670401    6180...  |1967-04-01 16:12:20  |FIN         |\n",
      "|19670402-012108FIN196721967040119670402     818...  |1967-04-02 01:21:08  |FIN         |\n",
      "|19670402-140519FIN196721967040119670402    3590...  |1967-04-02 14:05:19  |FIN         |\n",
      "|19670403-051650FIN196721967040119670403    6457...  |1967-04-03 05:16:50  |FIN         |\n",
      "|19670403-194201FIN196721967040119670403    6692...  |1967-04-03 19:42:01  |FIN         |\n",
      "|19670404-011711FIN196721967040119670404    5352...  |1967-04-04 01:17:11  |FIN         |\n",
      "|19670404-023010FIN196721967040119670404    7901...  |1967-04-04 02:30:10  |FIN         |\n",
      "|19670404-072732FIN196721967040119670404    8417...  |1967-04-04 07:27:32  |FIN         |\n",
      "|19670404-134250FIN196721967040119670404    5765...  |1967-04-04 13:42:50  |FIN         |\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# These are fixed-width fields, so read the entire line in as \"line\"\n",
    "schema = StructType([\n",
    "        StructField(\"line\", StringType(), False),\n",
    "])\n",
    "\n",
    "# generic dataframe for all record types\n",
    "# create a temporary table\n",
    "# The delimiter '|' seems safer\n",
    "df = (\n",
    "    session\n",
    "    .read\n",
    "    .schema(schema)\n",
    "    .option('field_delimiter', '|')\n",
    "    .csv(stage_path)\n",
    "    .with_column(\n",
    "        'pts', \n",
    "        to_timestamp(\n",
    "            substring(col(\"line\"), lit(0), lit(15)), \n",
    "            lit(\"yyyymmdd-hhmiss\")\n",
    "        )\n",
    "    )\n",
    "    .with_column(\n",
    "        'rec_type', \n",
    "        substring(col(\"line\"), lit(16), lit(3))\n",
    "    )\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .save_as_table(\"finwire\", table_type=\"temporary\")\n",
    ")\n",
    "\n",
    "# let's see the table\n",
    "df = (\n",
    "    session \n",
    "    .table('finwire') \n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can create the three separate tables from this temporary table using `WITH_COLUMN` and `SUBSTRING`.\n",
    "\n",
    "I'll only show the Security table as an example, but the other two are done the same way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEC table created.\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"PTS\"                |\"SYMBOL\"         |\"ISSUE_TYPE\"  |\"STATUS\"  |\"NAME\"                                              |\"EX_ID\"  |\"SH_OUT\"       |\"FIRST_TRADE_DATE\"  |\"FIRST_EXCHANGE_DATE\"  |\"DIVIDEND\"    |\"CO_NAME_OR_CIK\"                                    |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|1968-06-12 02:43:03  |AAAAAAAAAAAAAJG  |COMMON        |ACTV      |rFALDSWBSGSnzzMwTwjF                           ...  |PCX      |792341095      |19230923            |19301212               |        0.68  |dGTSaPOJMHvtCCHelvrPOQXnY                      ...  |\n",
      "|1968-06-14 10:29:54  |AAAAAAAAAAAAAJF  |COMMON        |ACTV      |tZVXPNivYmcKiIoOwwGzwKftrcpUPDkCQKoKbPbBFvEcH  ...  |AMEX     |848522297      |18890530            |19210419               |        0.54  |nFkXCFIQQcAPOHRuYtieKkGSZpAdCmvxWPuheWUSLiFkN  ...  |\n",
      "|1968-06-14 17:01:23  |AAAAAAAAAAAAAJE  |COMMON        |ACTV      |UtoEIg aYYaIOZHqbaoiIfKAFeYAefmUjkCQrFFtSeJsFiB...  |NYSE     |506721656      |19300608            |18691015               |        1.30  |0000000072                                          |\n",
      "|1968-06-14 20:30:54  |AAAAAAAAAAAAAJD  |COMMON        |ACTV      |OStNwLwpIlLRvMVQEGigfSHHsYzqKWRpyXIXiAcOH      ...  |NASDAQ   |364968850      |19010826            |19661108               |        0.93  |dBBCsCzeivSxrOWJZkMbNfLitfJSVqvvAy             ...  |\n",
      "|1968-06-16 10:58:30  |AAAAAAAAAAAAAJC  |COMMON        |ACTV      |RtffDRwxjXdhGANMNfZRKFByDpnKfFHkBIPJtGOOJCDVINq...  |PCX      |643887645      |18750523            |19411123               |        0.45  |zScyndwxOcLUXIwtrdKPFPDeQiYudN                 ...  |\n",
      "|1968-06-17 06:24:16  |AAAAAAAAAAAAAJB  |COMMON        |ACTV      |bQiPAhBJXYqJnNhIugWOBQZRI                      ...  |NASDAQ   |769161945      |19180731            |19540313               |        0.41  |0000000077                                          |\n",
      "|1968-06-17 23:30:19  |AAAAAAAAAAAAAJA  |PREF_A        |ACTV      |KQNCmlNrCaKozrTtwxjFtXtOLUEymubHULanCRApTUOCOoN...  |AMEX     |608656022      |19561206            |18690708               |        2.44  |0000000014                                          |\n",
      "|1968-06-18 03:56:09  |AAAAAAAAAAAAAIZ  |COMMON        |ACTV      |wtERZLMKsSYbyScRwKWFhAKuuJRqFbETvejObbEQDSd ods...  |NYSE     |601651039      |18700414            |18980108               |        2.32  |0000000012                                          |\n",
      "|1968-06-18 06:05:36  |AAAAAAAAAAAAAIY  |COMMON        |ACTV      |FieMLbpaoNUcUBPjwgHlDZdQwGxzQfBIaUTXRhHGdHkX WI...  |PCX      |784709609      |18800601            |18690309               |        2.45  |0000000035                                          |\n",
      "|1968-06-19 12:29:40  |AAAAAAAAAAAAAGD  |COMMON        |INAC      |yaVsFhUzAcjyhMIjAQgqWRANniFatEH k              ...  |NASDAQ   |131790475      |19160607            |19220828               |        0.17  |0000000072                                          |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SEC record types\n",
    "table_name = 'sec'\n",
    "df = (\n",
    "    session\n",
    "    .table('finwire')\n",
    "    .where(col('rec_type') == 'SEC')\n",
    "    .withColumn(\n",
    "        'symbol', \n",
    "        substring(col(\"line\"), lit(19), lit(15))\n",
    "    )\n",
    "    .withColumn(\n",
    "        'issue_type', \n",
    "        substring(col(\"line\"), lit(34), lit(6))\n",
    "    )\n",
    "    .withColumn(\n",
    "        'status', \n",
    "        substring(col(\"line\"), lit(40), lit(4))\n",
    "    )\n",
    "    .withColumn(\n",
    "        'name', \n",
    "        substring(col(\"line\"), lit(44), lit(70))\n",
    "    )\n",
    "    .withColumn(\n",
    "        'ex_id', \n",
    "        substring(col(\"line\"), lit(114), lit(6))\n",
    "    )\n",
    "    .withColumn(\n",
    "        'sh_out', \n",
    "        substring(col(\"line\"), lit(120), lit(13))\n",
    "    )\n",
    "    .withColumn(\n",
    "        'first_trade_date', \n",
    "        substring(col(\"line\"), lit(133), lit(8))\n",
    "    )\n",
    "    .withColumn(\n",
    "        'first_exchange_date', \n",
    "        substring(col(\"line\"), lit(141), lit(8))\n",
    "    )\n",
    "    .withColumn(\n",
    "        'dividend', \n",
    "        substring(col(\"line\"), lit(149), lit(12))\n",
    "    )\n",
    "    .withColumn(\n",
    "        'co_name_or_cik', \n",
    "        substring(col(\"line\"), lit(161), lit(60))\n",
    "    )\n",
    "    .drop(col(\"line\"), col(\"rec_type\"))\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .save_as_table(table_name)\n",
    ")\n",
    "\n",
    "print(f\"{table_name.upper()} table created.\")\n",
    "\n",
    "# let's see the table\n",
    "df = (\n",
    "    session \n",
    "    .table('sec') \n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DIGen.jar` utility creates a single XML called `CustomerMgmt.xml`, with a sample below:\n",
    "\n",
    "```xml\n",
    "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<TPCDI:Actions xmlns:TPCDI=\"http://www.tpc.org/tpc-di\">\n",
    " <TPCDI:Action ActionType=\"NEW\" ActionTS=\"2007-07-07T02:56:25\">\n",
    "  <Customer C_ID=\"0\" C_TAX_ID=\"923-54-6498\" C_GNDR=\"F\" C_TIER=\"3\" C_DOB=\"1940-12-02\">\n",
    "   <Name>\n",
    "    <C_L_NAME>Joannis</C_L_NAME>\n",
    "    <C_F_NAME>Adara</C_F_NAME>\n",
    "    <C_M_NAME/>\n",
    "   </Name>\n",
    "   <Address>\n",
    "    <C_ADLINE1>4779 Weller Way</C_ADLINE1>\n",
    "    <C_ADLINE2/>\n",
    "    <C_ZIPCODE>92624</C_ZIPCODE>\n",
    "    <C_CITY>Columbus</C_CITY>\n",
    "    <C_STATE_PROV>Ontario</C_STATE_PROV>\n",
    "    <C_CTRY>Canada</C_CTRY>\n",
    "   </Address>\n",
    "   <ContactInfo>\n",
    "    <C_PRIM_EMAIL>Adara.Joannis@moose-mail.com</C_PRIM_EMAIL>\n",
    "    <C_ALT_EMAIL>Adara.Joannis@gmx.com</C_ALT_EMAIL>\n",
    "    <C_PHONE_1>\n",
    "     <C_CTRY_CODE>1</C_CTRY_CODE>\n",
    "     <C_AREA_CODE>872</C_AREA_CODE>\n",
    "     <C_LOCAL>523-8928</C_LOCAL>\n",
    "     <C_EXT/>\n",
    "    </C_PHONE_1>\n",
    "    <C_PHONE_2>\n",
    "     <C_CTRY_CODE/>\n",
    "     <C_AREA_CODE/>\n",
    "     <C_LOCAL>492-3961</C_LOCAL>\n",
    "     <C_EXT/>\n",
    "    </C_PHONE_2>\n",
    "    <C_PHONE_3>\n",
    "     <C_CTRY_CODE/>\n",
    "     <C_AREA_CODE/>\n",
    "     <C_LOCAL/>\n",
    "     <C_EXT/>\n",
    "    </C_PHONE_3>\n",
    "   </ContactInfo>\n",
    "   <TaxInfo>\n",
    "    <C_LCL_TX_ID>CA3</C_LCL_TX_ID>\n",
    "    <C_NAT_TX_ID>YT3</C_NAT_TX_ID>\n",
    "   </TaxInfo>\n",
    "   <Account CA_ID=\"0\" CA_TAX_ST=\"1\">\n",
    "    <CA_B_ID>17713</CA_B_ID>\n",
    "    <CA_NAME>CJlmMuFyibKOmKLHIaTeWugvCgZdmcfpDsYb</CA_NAME>\n",
    "   </Account>\n",
    "  </Customer>\n",
    " </TPCDI:Action>\n",
    "</TPCDI:Actions>\n",
    "```\n",
    "\n",
    "The hierarchical representation of a TPCDI:Action record, with @ signifying a node attribute as opposed to an element, is shown below:\n",
    "\n",
    "```\n",
    "|-- TPCDI:Action\n",
    "    |-- @ActionType: string\n",
    "    |-- @ActionTS: timestamp\n",
    "    |-- Customer\n",
    "        |-- @C_ID: number\n",
    "        |-- @C_TAX_ID: string\n",
    "        |-- @C_GNDR: string\n",
    "        |-- @C_TIER: number\n",
    "        |-- @C_DOB: date\n",
    "        |-- Name\n",
    "            |-- C_F_NAME: string\n",
    "            |-- C_L_NAME: string\n",
    "            |-- C_M_NAME: string\n",
    "        |-- Address\n",
    "            |-- C_ADLINE1: string\n",
    "            |-- C_ADLINE2: string\n",
    "            |-- C_CITY: string\n",
    "            |-- C_CTRY: string\n",
    "            |-- C_STATE_PROV: string\n",
    "            |-- C_ZIPCODE: string\n",
    "        |-- ContactInfo\n",
    "            |-- C_ALT_EMAIL: string\n",
    "            |-- C_PHONE_1\n",
    "                |-- C_AREA_CODE: number\n",
    "                |-- C_CTRY_CODE: number\n",
    "                |-- C_EXT: long\n",
    "                |-- C_LOCAL: string\n",
    "            |-- C_PHONE_2\n",
    "                |-- C_AREA_CODE: number\n",
    "                |-- C_CTRY_CODE: number\n",
    "                |-- C_EXT: number\n",
    "                |-- C_LOCAL: string\n",
    "            |-- C_PHONE_3\n",
    "                |-- C_AREA_CODE: number\n",
    "                |-- C_CTRY_CODE: number\n",
    "                |-- C_EXT: number\n",
    "                |-- C_LOCAL: string\n",
    "        |-- TaxInfo\n",
    "            |-- C_LCL_TX_ID: string\n",
    "            |-- C_NAT_TX_ID: string\n",
    "        |-- Account\n",
    "            |-- CA_B_ID: number\n",
    "            |-- CA_NAME: string\n",
    "            |-- @CA_ID: number\n",
    "            |-- @CA_TAX_ST: number\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a DataFrame from the XML file and see what we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File CustomerMgmt.xml: SKIPPED\n",
      "-----------------------------------------------------------------------------------------\n",
      "|\"$1\"                                                                                   |\n",
      "-----------------------------------------------------------------------------------------\n",
      "|<TPCDI:Action ActionTS=\"2007-07-07T04:28:56\" ActionType=\"NEW\">                         |\n",
      "|  <Customer C_DOB=\"1940-12-02\" C_GNDR=\"F\" C_ID=\"0\" C_TAX_ID=\"923-54-6498\" C_TIER=\"3\">  |\n",
      "|    <Name>                                                                             |\n",
      "|      <C_L_NAME>Joannis</C_L_NAME>                                                     |\n",
      "|      <C_F_NAME>Adara</C_F_NAME>                                                       |\n",
      "|      <C_M_NAME></C_M_NAME>                                                            |\n",
      "|    </Name>                                                                            |\n",
      "|    <Address>                                                                          |\n",
      "|      <C_ADLINE1>4779 Weller Way</C_ADLINE1>                                           |\n",
      "|      <C_ADLINE2></C_ADLINE2>                                                          |\n",
      "|      <C_ZIPCODE>92624</C_ZIPCODE>                                                     |\n",
      "|      <C_CITY>Columbus</C_CITY>                                                        |\n",
      "|      <C_STATE_PROV>Ontario</C_STATE_PROV>                                             |\n",
      "|      <C_CTRY>Canada</C_CTRY>                                                          |\n",
      "|    </Address>                                                                         |\n",
      "|    <ContactInfo>                                                                      |\n",
      "|      <C_PRIM_EMAIL>Adara.Joannis@moose-mail.com</C_PRIM_EMAIL>                        |\n",
      "|      <C_ALT_EMAIL>Adara.Joannis@gmx.com</C_ALT_EMAIL>                                 |\n",
      "|      <C_PHONE_1>                                                                      |\n",
      "|        <C_CTRY_CODE>1</C_CTRY_CODE>                                                   |\n",
      "|        <C_AREA_CODE>872</C_AREA_CODE>                                                 |\n",
      "|        <C_LOCAL>523-8928</C_LOCAL>                                                    |\n",
      "|        <C_EXT></C_EXT>                                                                |\n",
      "|      </C_PHONE_1>                                                                     |\n",
      "|      <C_PHONE_2>                                                                      |\n",
      "|        <C_CTRY_CODE></C_CTRY_CODE>                                                    |\n",
      "|        <C_AREA_CODE></C_AREA_CODE>                                                    |\n",
      "|        <C_LOCAL>492-3961</C_LOCAL>                                                    |\n",
      "|        <C_EXT></C_EXT>                                                                |\n",
      "|      </C_PHONE_2>                                                                     |\n",
      "|      <C_PHONE_3>                                                                      |\n",
      "|        <C_CTRY_CODE></C_CTRY_CODE>                                                    |\n",
      "|        <C_AREA_CODE></C_AREA_CODE>                                                    |\n",
      "|        <C_LOCAL></C_LOCAL>                                                            |\n",
      "|        <C_EXT></C_EXT>                                                                |\n",
      "|      </C_PHONE_3>                                                                     |\n",
      "|    </ContactInfo>                                                                     |\n",
      "|    <TaxInfo>                                                                          |\n",
      "|      <C_LCL_TX_ID>CA3</C_LCL_TX_ID>                                                   |\n",
      "|      <C_NAT_TX_ID>YT3</C_NAT_TX_ID>                                                   |\n",
      "|    </TaxInfo>                                                                         |\n",
      "|    <Account CA_ID=\"0\" CA_TAX_ST=\"1\">                                                  |\n",
      "|      <CA_B_ID>15746</CA_B_ID>                                                         |\n",
      "|      <CA_NAME>CJlmMuFyibKOmKLHIaTeWugvCgZdmcfpDsYb</CA_NAME>                          |\n",
      "|    </Account>                                                                         |\n",
      "|  </Customer>                                                                          |\n",
      "|</TPCDI:Action>                                                                        |\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "stage_path = \"@tpcdi/Batch1\"\n",
    "\n",
    "# Put the file\n",
    "put_result = (\n",
    "    session\n",
    "    .file\n",
    "    .put(\n",
    "        f\"{source_path}/CustomerMgmt.xml\",\n",
    "        f\"{stage_path}/CustomerMgmt.xml\",\n",
    "        parallel=4,\n",
    "        auto_compress=True,\n",
    "    )\n",
    ")\n",
    "for result in put_result:\n",
    "    print(f\"File {result.source}: {result.status}\")\n",
    "\n",
    "# Read the XML file into a DataFrame and show it\n",
    "df = (\n",
    "    session\n",
    "    .read\n",
    "    .option('STRIP_OUTER_ELEMENT', True) # Strips TPCDI:Actions\n",
    "    .xml(f\"{stage_path}/CustomerMgmt.xml\")\n",
    "    .show(1, 100)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Snowflake does not support simple dot notation for XML the way it does for JSON.\n",
    "\n",
    "Instead we have to pair the `GET()` function with an `XMLGET()`, which can be quite tedious.\n",
    "\n",
    "So I wrote a few helper functions to encapsulate that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplifies retrieving XML elements\n",
    "def get_xml_element(\n",
    "        column:str,\n",
    "        element:str,\n",
    "        datatype:str,\n",
    "        with_alias:bool = True\n",
    "):\n",
    "    new_element = (\n",
    "        get(\n",
    "            xmlget(\n",
    "                col(column),\n",
    "                lit(element),\n",
    "            ),\n",
    "            lit('$')\n",
    "        )\n",
    "        .cast(datatype)\n",
    "    )\n",
    "\n",
    "    # alias needs to be optional\n",
    "    return (\n",
    "        new_element.alias(element) if with_alias else new_element\n",
    "    )\n",
    "\n",
    "# Simplifies retrieving XML attributes\n",
    "def get_xml_attribute(\n",
    "        column:str,\n",
    "        attribute:str,\n",
    "        datatype:str,\n",
    "        with_alias:bool = True\n",
    "):\n",
    "    new_attribute = (\n",
    "        get(\n",
    "            col(column),\n",
    "            lit(f\"@{attribute}\")\n",
    "        )\n",
    "        .cast(datatype)\n",
    "    )\n",
    "\n",
    "    # alias needs to be optional\n",
    "    return (\n",
    "        new_attribute.alias(attribute) if with_alias else new_attribute\n",
    "    )\n",
    "\n",
    "# Constructs a phone number from multiple nested fields\n",
    "def get_phone_number(\n",
    "        phone_id:str,\n",
    "        separator:str = '-'\n",
    "):\n",
    "    return (\n",
    "        concat (\n",
    "            get_xml_element(f\"phone{phone_id}\", 'C_CTRY_CODE', 'STRING', False),\n",
    "            when(get_xml_element(f\"phone{phone_id}\", 'C_CTRY_CODE', 'STRING', False) == '', '')\n",
    "            .otherwise(separator),\n",
    "            get_xml_element(f\"phone{phone_id}\", 'C_AREA_CODE', 'STRING', False),\n",
    "            when(get_xml_element(f\"phone{phone_id}\", 'C_AREA_CODE', 'STRING', False) == '', '')\n",
    "            .otherwise(separator),\n",
    "            get_xml_element(f\"phone{phone_id}\", 'C_LOCAL', 'STRING', False),\n",
    "            when(get_xml_element(f\"phone{phone_id}\", 'C_EXT', 'STRING', False) == '', '')\n",
    "            .otherwise(\" ext: \"),\n",
    "            get_xml_element(f\"phone{phone_id}\", 'C_EXT', 'STRING', False)\n",
    "        )\n",
    "        .alias(f\"c_phone_{phone_id}\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's put it all together and create our `customer_mgmt` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUSTOMER_MGMT table created.\n",
      "---------------------------------------------------------------------\n",
      "|\"ACTION_TS\"          |\"C_ID\"  |\"C_TIER\"  |\"C_PHONE_1\"              |\n",
      "---------------------------------------------------------------------\n",
      "|2007-07-07 04:28:56  |0       |3         |1-872-523-8928           |\n",
      "|2007-07-07 04:47:03  |1       |3         |767-4707                 |\n",
      "|2007-07-07 06:17:28  |2       |3         |420-757-3642 ext: 61998  |\n",
      "|2007-07-07 07:57:28  |3       |3         |1-819-163-0774           |\n",
      "|2007-07-07 09:38:29  |4       |NULL      |734-4072                 |\n",
      "|2007-07-07 11:35:54  |5       |3         |667-588-0328             |\n",
      "|2007-07-07 15:00:43  |6       |3         |1-475-246-3524           |\n",
      "|2007-07-07 21:05:32  |7       |3         |466-5901                 |\n",
      "|2007-07-08 00:32:37  |8       |NULL      |540-4805                 |\n",
      "|2007-07-08 04:14:53  |9       |NULL      |230-135-8787             |\n",
      "---------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_name = 'customer_mgmt'\n",
    "df = (\n",
    "    session\n",
    "    .read\n",
    "    .option('STRIP_OUTER_ELEMENT', True) # Strips the TPCDI:Actions node\n",
    "    .xml(f\"{stage_path}/CustomerMgmt.xml\")\n",
    "    .select(\n",
    "        # flatten out all of the nested elements\n",
    "        xmlget(col('$1'), lit('Customer'), 0).alias('customer'),\n",
    "        xmlget(col('customer'), lit('Name'), 0).alias('name'),\n",
    "        xmlget(col('customer'), lit('Address'), 0).alias('address'),\n",
    "        xmlget(col('customer'), lit('ContactInfo'), 0).alias('contact_info'),\n",
    "        xmlget(col('contact_info'), lit('C_PHONE_1')).alias('phone1'),\n",
    "        xmlget(col('contact_info'), lit('C_PHONE_2')).alias('phone2'),\n",
    "        xmlget(col('contact_info'), lit('C_PHONE_3')).alias('phone3'),\n",
    "        xmlget(col('customer'), lit('TaxInfo'), 0).alias('tax_info'),\n",
    "        xmlget(col('customer'), lit('Account'), 0).alias('account'),\n",
    "        # get the Action attributes\n",
    "        get_xml_attribute('$1','ActionType','STRING'),\n",
    "        get_xml_attribute('$1','ActionTS','STRING'),\n",
    "    )\n",
    "    .select(\n",
    "        # Handling Action attributes\n",
    "        to_timestamp(\n",
    "            col('ActionTs'),\n",
    "            lit('yyyy-mm-ddThh:mi:ss')\n",
    "        ).alias('action_ts'),\n",
    "        col('ActionType').alias('ACTION_TYPE'),\n",
    "        # Get Customer Attributes\n",
    "        get_xml_attribute('customer','C_ID','NUMBER'),\n",
    "        get_xml_attribute('customer','C_TAX_ID','STRING'),\n",
    "        get_xml_attribute('customer','C_GNDR','STRING'),\n",
    "        # Had to disable auto-aliasing\n",
    "        try_cast(\n",
    "            get_xml_attribute('customer','C_TIER','STRING', False),\n",
    "            'NUMBER'\n",
    "        ).alias('c_tier'),\n",
    "        get_xml_attribute('customer','C_DOB','DATE'),\n",
    "        # Get Name elements\n",
    "        get_xml_element('name','C_L_NAME','STRING'),\n",
    "        get_xml_element('name','C_F_NAME','STRING'),\n",
    "        get_xml_element('name','C_M_NAME','STRING'),\n",
    "        # Get Address elements\n",
    "        get_xml_element('address','C_ADLINE1','STRING'),\n",
    "        get_xml_element('address', 'C_ADLINE2', 'STRING'),\n",
    "        get_xml_element('address','C_ZIPCODE','STRING'),\n",
    "        get_xml_element('address','C_CITY','STRING'),\n",
    "        get_xml_element('address','C_STATE_PROV','STRING'),\n",
    "        get_xml_element('address','C_CTRY','STRING'),\n",
    "        # Get Contact Info elements\n",
    "        get_xml_element('contact_info','C_PRIM_EMAIL','STRING'),\n",
    "        get_xml_element('contact_info','C_ALT_EMAIL','STRING'),\n",
    "        # Contruct phone numbers from multi-nested elements\n",
    "        get_phone_number('1'),\n",
    "        get_phone_number('2'),\n",
    "        get_phone_number('3'),\n",
    "        # Get TaxInfo elements\n",
    "        get_xml_element('tax_info','C_LCL_TX_ID','STRING'),\n",
    "        get_xml_element('tax_info','C_NAT_TX_ID','STRING'),\n",
    "        # Get Account Attributes\n",
    "        get_xml_attribute('account','CA_ID','STRING'),\n",
    "        get_xml_attribute('account','CA_TAX_ST','NUMBER'),\n",
    "        # Get Account elements\n",
    "        get_xml_element('account','CA_B_ID','NUMBER'),\n",
    "        get_xml_element('account','CA_NAME','STRING'),\n",
    "    )\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .save_as_table(table_name)\n",
    ")\n",
    "\n",
    "print(f\"{table_name.upper()} table created.\")\n",
    "\n",
    "df = (\n",
    "    session\n",
    "    .table('customer_mgmt')\n",
    "    .select(\n",
    "        col('action_ts'),\n",
    "        col('c_id'),\n",
    "        col('c_tier'),\n",
    "        col('c_phone_1')\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ETL Diagram](images/tpc-di-logical-model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442d9973-dcdb-491f-82d2-0a1ec2d133aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "# When we Google \"dbt dynamic tables\":\n",
    "\n",
    "![Google Search](images/dbt-dynamic-tables.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73ac995-dcdf-4d7d-96d8-4f23eafc16c9",
   "metadata": {},
   "source": [
    "# It's not as simple as this.\n",
    "\n",
    "![Conflict](images/refresh-conflict.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e4236c-46da-4b50-aa37-225df6ff9f7f",
   "metadata": {},
   "source": [
    "# dbt is more than just a job scheduler.\n",
    "Dynamic Tables need to be (re)created in the correct order. This can become very complex as the number of tables and dependencies increases.\n",
    "\n",
    "dbt understands your DAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b6de585-2299-4039-bce3-cf27ad5290d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m21:23:19  Running with dbt=1.7.2\n",
      "\u001b[0m21:23:19  Registered adapter: snowflake=1.7.0\n",
      "\u001b[0m21:23:19  Found 45 models, 17 sources, 0 exposures, 0 metrics, 544 macros, 0 groups, 0 semantic models\n",
      "\u001b[0m21:23:19  \n",
      "\u001b[0m21:23:22  Concurrency: 20 threads (target='dev')\n",
      "\u001b[0m21:23:22  \n",
      "\u001b[0m21:23:22  Building catalog\n",
      "\u001b[0m21:23:29  Catalog written to /Users/stewartbryson/Source/dbt-tpcdi/target/catalog.json\n",
      "\u001b[0m21:23:30  Running with dbt=1.7.2\n",
      "Serving docs at 8080\n",
      "To access from your browser, navigate to: http://localhost:8080\n",
      "\n",
      "\n",
      "\n",
      "Press Ctrl+C to exit.\n",
      "127.0.0.1 - - [27/Nov/2023 16:23:31] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [27/Nov/2023 16:23:31] \"GET /manifest.json?cb=1701120211638 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [27/Nov/2023 16:23:31] \"GET /catalog.json?cb=1701120211638 HTTP/1.1\" 200 -\n",
      "^C\n",
      "\u001b[0m21:24:08  Encountered an error:\n",
      "\n",
      "\u001b[0m21:24:08  Traceback (most recent call last):\n",
      "  File \"/Users/stewartbryson/anaconda3/envs/tpcdi/lib/python3.8/site-packages/dbt/cli/requires.py\", line 90, in wrapper\n",
      "    result, success = func(*args, **kwargs)\n",
      "  File \"/Users/stewartbryson/anaconda3/envs/tpcdi/lib/python3.8/site-packages/dbt/cli/requires.py\", line 75, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/stewartbryson/anaconda3/envs/tpcdi/lib/python3.8/site-packages/dbt/cli/requires.py\", line 168, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/stewartbryson/anaconda3/envs/tpcdi/lib/python3.8/site-packages/dbt/cli/requires.py\", line 197, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/stewartbryson/anaconda3/envs/tpcdi/lib/python3.8/site-packages/dbt/cli/requires.py\", line 244, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/stewartbryson/anaconda3/envs/tpcdi/lib/python3.8/site-packages/dbt/cli/main.py\", line 324, in docs_serve\n",
      "    results = task.run()\n",
      "  File \"/Users/stewartbryson/anaconda3/envs/tpcdi/lib/python3.8/site-packages/dbt/task/serve.py\", line 28, in run\n",
      "    httpd.serve_forever()\n",
      "  File \"/Users/stewartbryson/anaconda3/envs/tpcdi/lib/python3.8/socketserver.py\", line 232, in serve_forever\n",
      "    ready = selector.select(poll_interval)\n",
      "  File \"/Users/stewartbryson/anaconda3/envs/tpcdi/lib/python3.8/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!dbt docs generate\n",
    "!dbt docs serve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469f485d-792c-46df-906f-cd09f364d7d0",
   "metadata": {},
   "source": [
    "### We can see all that's required to enable dynamic tables in our `dbt_project.yml` file:\n",
    "\n",
    "```yaml\n",
    "models:\n",
    "  dbt_tpcdi:\n",
    "    example:\n",
    "      +materialized: view\n",
    "    bronze:\n",
    "      +schema: bronze\n",
    "      +materialized: dynamic_table\n",
    "      +snowflake_warehouse: tpcdi_large\n",
    "      +target_lag: downstream\n",
    "    silver:\n",
    "      +schema: silver\n",
    "      +materialized: dynamic_table\n",
    "      +snowflake_warehouse: tpcdi_large\n",
    "      +target_lag: '10 minutes'\n",
    "    gold:\n",
    "      +schema: gold\n",
    "      +materialized: dynamic_table\n",
    "      +snowflake_warehouse: tpcdi_large\n",
    "      +target_lag: '20 minutes'\n",
    "    work:\n",
    "      +schema: work\n",
    "      +materialized: ephemeral\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "420db6a7-ce06-4638-a3a5-1ac16aff2fc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m21:26:43  Running with dbt=1.7.2\n",
      "\u001b[0m21:26:43  Registered adapter: snowflake=1.7.0\n",
      "\u001b[0m21:26:43  Found 45 models, 17 sources, 0 exposures, 0 metrics, 544 macros, 0 groups, 0 semantic models\n",
      "\u001b[0m21:26:43  \n",
      "\u001b[0m21:26:45  Concurrency: 20 threads (target='dev')\n",
      "\u001b[0m21:26:45  \n",
      "\u001b[0m21:26:45  1 of 44 START sql dynamic_table model dl_bronze.brokerage_cash_transaction ..... [RUN]\n",
      "\u001b[0m21:26:45  2 of 44 START sql dynamic_table model dl_bronze.brokerage_daily_market ......... [RUN]\n",
      "\u001b[0m21:26:45  3 of 44 START sql dynamic_table model dl_bronze.brokerage_holding_history ...... [RUN]\n",
      "\u001b[0m21:26:45  4 of 44 START sql dynamic_table model dl_bronze.brokerage_trade ................ [RUN]\n",
      "\u001b[0m21:26:45  5 of 44 START sql dynamic_table model dl_bronze.brokerage_trade_history ........ [RUN]\n",
      "\u001b[0m21:26:45  6 of 44 START sql dynamic_table model dl_bronze.brokerage_watch_history ........ [RUN]\n",
      "\u001b[0m21:26:45  7 of 44 START sql dynamic_table model dl_bronze.crm_customer_mgmt .............. [RUN]\n",
      "\u001b[0m21:26:45  8 of 44 START sql dynamic_table model dl_bronze.finwire_company ................ [RUN]\n",
      "\u001b[0m21:26:45  9 of 44 START sql dynamic_table model dl_bronze.finwire_financial .............. [RUN]\n",
      "\u001b[0m21:26:45  10 of 44 START sql dynamic_table model dl_bronze.finwire_security .............. [RUN]\n",
      "\u001b[0m21:26:45  11 of 44 START sql dynamic_table model dl_bronze.hr_employee ................... [RUN]\n",
      "\u001b[0m21:26:45  12 of 44 START sql dynamic_table model dl_bronze.reference_date ................ [RUN]\n",
      "\u001b[0m21:26:45  13 of 44 START sql dynamic_table model dl_bronze.reference_industry ............ [RUN]\n",
      "\u001b[0m21:26:45  14 of 44 START sql dynamic_table model dl_bronze.reference_status_type ......... [RUN]\n",
      "\u001b[0m21:26:45  15 of 44 START sql dynamic_table model dl_bronze.reference_tax_rate ............ [RUN]\n",
      "\u001b[0m21:26:45  16 of 44 START sql dynamic_table model dl_bronze.reference_trade_type .......... [RUN]\n",
      "\u001b[0m21:26:45  17 of 44 START sql dynamic_table model dl_bronze.syndicated_prospect ........... [RUN]\n",
      "\u001b[0m21:26:47  15 of 44 OK created sql dynamic_table model dl_bronze.reference_tax_rate ....... [\u001b[32mSUCCESS 1\u001b[0m in 2.18s]\n",
      "\u001b[0m21:26:48  13 of 44 OK created sql dynamic_table model dl_bronze.reference_industry ....... [\u001b[32mSUCCESS 1\u001b[0m in 2.55s]\n",
      "\u001b[0m21:26:48  12 of 44 OK created sql dynamic_table model dl_bronze.reference_date ........... [\u001b[32mSUCCESS 1\u001b[0m in 2.55s]\n",
      "\u001b[0m21:26:48  16 of 44 OK created sql dynamic_table model dl_bronze.reference_trade_type ..... [\u001b[32mSUCCESS 1\u001b[0m in 2.51s]\n",
      "\u001b[0m21:26:48  18 of 44 START sql dynamic_table model dl_silver.date .......................... [RUN]\n",
      "\u001b[0m21:26:48  10 of 44 OK created sql dynamic_table model dl_bronze.finwire_security ......... [\u001b[32mSUCCESS 1\u001b[0m in 2.66s]\n",
      "\u001b[0m21:26:48  8 of 44 OK created sql dynamic_table model dl_bronze.finwire_company ........... [\u001b[32mSUCCESS 1\u001b[0m in 2.78s]\n",
      "\u001b[0m21:26:48  14 of 44 OK created sql dynamic_table model dl_bronze.reference_status_type .... [\u001b[32mSUCCESS 1\u001b[0m in 2.84s]\n",
      "\u001b[0m21:26:48  19 of 44 START sql dynamic_table model dl_silver.companies ..................... [RUN]\n",
      "\u001b[0m21:26:48  17 of 44 OK created sql dynamic_table model dl_bronze.syndicated_prospect ...... [\u001b[32mSUCCESS 1\u001b[0m in 2.92s]\n",
      "\u001b[0m21:26:48  11 of 44 OK created sql dynamic_table model dl_bronze.hr_employee .............. [\u001b[32mSUCCESS 1\u001b[0m in 3.25s]\n",
      "\u001b[0m21:26:48  20 of 44 START sql dynamic_table model dl_silver.employees ..................... [RUN]\n",
      "\u001b[0m21:26:48  7 of 44 OK created sql dynamic_table model dl_bronze.crm_customer_mgmt ......... [\u001b[32mSUCCESS 1\u001b[0m in 3.28s]\n",
      "\u001b[0m21:26:48  21 of 44 START sql dynamic_table model dl_silver.accounts ...................... [RUN]\n",
      "\u001b[0m21:26:48  22 of 44 START sql dynamic_table model dl_silver.customers ..................... [RUN]\n",
      "\u001b[0m21:26:49  9 of 44 OK created sql dynamic_table model dl_bronze.finwire_financial ......... [\u001b[32mSUCCESS 1\u001b[0m in 4.52s]\n",
      "\u001b[0m21:26:50  18 of 44 OK created sql dynamic_table model dl_silver.date ..................... [\u001b[32mSUCCESS 1\u001b[0m in 2.11s]\n",
      "\u001b[0m21:26:50  23 of 44 START sql dynamic_table model dl_gold.dim_date ........................ [RUN]\n",
      "\u001b[0m21:26:50  20 of 44 OK created sql dynamic_table model dl_silver.employees ................ [\u001b[32mSUCCESS 1\u001b[0m in 2.08s]\n",
      "\u001b[0m21:26:50  24 of 44 START sql dynamic_table model dl_gold.dim_broker ...................... [RUN]\n",
      "\u001b[0m21:26:50  22 of 44 OK created sql dynamic_table model dl_silver.customers ................ [\u001b[32mSUCCESS 1\u001b[0m in 2.24s]\n",
      "\u001b[0m21:26:50  25 of 44 START sql dynamic_table model dl_gold.dim_customer .................... [RUN]\n",
      "\u001b[0m21:26:51  21 of 44 OK created sql dynamic_table model dl_silver.accounts ................. [\u001b[32mSUCCESS 1\u001b[0m in 2.48s]\n",
      "\u001b[0m21:26:51  19 of 44 OK created sql dynamic_table model dl_silver.companies ................ [\u001b[32mSUCCESS 1\u001b[0m in 2.92s]\n",
      "\u001b[0m21:26:51  26 of 44 START sql dynamic_table model dl_gold.dim_company ..................... [RUN]\n",
      "\u001b[0m21:26:51  27 of 44 START sql dynamic_table model dl_silver.financials .................... [RUN]\n",
      "\u001b[0m21:26:51  28 of 44 START sql dynamic_table model dl_silver.securities .................... [RUN]\n",
      "\u001b[0m21:26:51  1 of 44 OK created sql dynamic_table model dl_bronze.brokerage_cash_transaction  [\u001b[32mSUCCESS 1\u001b[0m in 6.10s]\n",
      "\u001b[0m21:26:51  29 of 44 START sql dynamic_table model dl_silver.cash_transactions ............. [RUN]\n",
      "\u001b[0m21:26:52  3 of 44 OK created sql dynamic_table model dl_bronze.brokerage_holding_history . [\u001b[32mSUCCESS 1\u001b[0m in 6.73s]\n",
      "\u001b[0m21:26:52  23 of 44 OK created sql dynamic_table model dl_gold.dim_date ................... [\u001b[32mSUCCESS 1\u001b[0m in 2.71s]\n",
      "\u001b[0m21:26:53  4 of 44 OK created sql dynamic_table model dl_bronze.brokerage_trade ........... [\u001b[32mSUCCESS 1\u001b[0m in 7.61s]\n",
      "\u001b[0m21:26:53  2 of 44 OK created sql dynamic_table model dl_bronze.brokerage_daily_market .... [\u001b[32mSUCCESS 1\u001b[0m in 8.29s]\n",
      "\u001b[0m21:26:53  30 of 44 START sql dynamic_table model dl_silver.daily_market .................. [RUN]\n",
      "\u001b[0m21:26:54  26 of 44 OK created sql dynamic_table model dl_gold.dim_company ................ [\u001b[32mSUCCESS 1\u001b[0m in 3.08s]\n",
      "\u001b[0m21:26:54  24 of 44 OK created sql dynamic_table model dl_gold.dim_broker ................. [\u001b[32mSUCCESS 1\u001b[0m in 4.00s]\n",
      "\u001b[0m21:26:55  29 of 44 OK created sql dynamic_table model dl_silver.cash_transactions ........ [\u001b[32mSUCCESS 1\u001b[0m in 3.27s]\n",
      "\u001b[0m21:26:55  25 of 44 OK created sql dynamic_table model dl_gold.dim_customer ............... [\u001b[32mSUCCESS 1\u001b[0m in 4.01s]\n",
      "\u001b[0m21:26:55  31 of 44 START sql dynamic_table model dl_gold.dim_account ..................... [RUN]\n",
      "\u001b[0m21:26:55  5 of 44 OK created sql dynamic_table model dl_bronze.brokerage_trade_history ... [\u001b[32mSUCCESS 1\u001b[0m in 9.82s]\n",
      "\u001b[0m21:26:55  32 of 44 START sql dynamic_table model dl_silver.trades_history ................ [RUN]\n",
      "\u001b[0m21:26:55  6 of 44 OK created sql dynamic_table model dl_bronze.brokerage_watch_history ... [\u001b[32mSUCCESS 1\u001b[0m in 9.97s]\n",
      "\u001b[0m21:26:56  27 of 44 OK created sql dynamic_table model dl_silver.financials ............... [\u001b[32mSUCCESS 1\u001b[0m in 5.60s]\n",
      "\u001b[0m21:26:56  28 of 44 OK created sql dynamic_table model dl_silver.securities ............... [\u001b[32mSUCCESS 1\u001b[0m in 5.69s]\n",
      "\u001b[0m21:26:56  33 of 44 START sql dynamic_table model dl_gold.dim_security .................... [RUN]\n",
      "\u001b[0m21:26:56  34 of 44 START sql dynamic_table model dl_silver.watches_history ............... [RUN]\n",
      "\u001b[0m21:26:57  30 of 44 OK created sql dynamic_table model dl_silver.daily_market ............. [\u001b[32mSUCCESS 1\u001b[0m in 3.39s]\n",
      "\u001b[0m21:26:58  31 of 44 OK created sql dynamic_table model dl_gold.dim_account ................ [\u001b[32mSUCCESS 1\u001b[0m in 3.91s]\n",
      "\u001b[0m21:26:58  35 of 44 START sql dynamic_table model dl_gold.fact_cash_transactions .......... [RUN]\n",
      "\u001b[0m21:26:59  33 of 44 OK created sql dynamic_table model dl_gold.dim_security ............... [\u001b[32mSUCCESS 1\u001b[0m in 2.80s]\n",
      "\u001b[0m21:26:59  36 of 44 START sql dynamic_table model dl_gold.fact_market_history ............. [RUN]\n",
      "\u001b[0m21:27:04  34 of 44 OK created sql dynamic_table model dl_silver.watches_history .......... [\u001b[32mSUCCESS 1\u001b[0m in 7.93s]\n",
      "\u001b[0m21:27:04  37 of 44 START sql dynamic_table model dl_silver.watches ....................... [RUN]\n",
      "\u001b[0m21:27:04  32 of 44 OK created sql dynamic_table model dl_silver.trades_history ........... [\u001b[32mSUCCESS 1\u001b[0m in 9.68s]\n",
      "\u001b[0m21:27:04  38 of 44 START sql dynamic_table model dl_gold.dim_trade ....................... [RUN]\n",
      "\u001b[0m21:27:04  39 of 44 START sql dynamic_table model dl_silver.trades ........................ [RUN]\n",
      "\u001b[0m21:27:05  35 of 44 OK created sql dynamic_table model dl_gold.fact_cash_transactions ..... [\u001b[32mSUCCESS 1\u001b[0m in 6.66s]\n",
      "\u001b[0m21:27:05  40 of 44 START sql dynamic_table model dl_gold.fact_cash_balances .............. [RUN]\n",
      "\u001b[0m21:27:10  37 of 44 OK created sql dynamic_table model dl_silver.watches .................. [\u001b[32mSUCCESS 1\u001b[0m in 6.10s]\n",
      "\u001b[0m21:27:10  41 of 44 START sql dynamic_table model dl_gold.fact_watches .................... [RUN]\n",
      "\u001b[0m21:27:12  39 of 44 OK created sql dynamic_table model dl_silver.trades ................... [\u001b[32mSUCCESS 1\u001b[0m in 7.09s]\n",
      "\u001b[0m21:27:12  42 of 44 START sql dynamic_table model dl_silver.holdings_history .............. [RUN]\n",
      "\u001b[0m21:27:20  38 of 44 OK created sql dynamic_table model dl_gold.dim_trade .................. [\u001b[32mSUCCESS 1\u001b[0m in 15.49s]\n",
      "\u001b[0m21:27:20  43 of 44 START sql dynamic_table model dl_gold.fact_trade ...................... [RUN]\n",
      "\u001b[0m21:27:22  42 of 44 OK created sql dynamic_table model dl_silver.holdings_history ......... [\u001b[32mSUCCESS 1\u001b[0m in 10.17s]\n",
      "\u001b[0m21:27:22  44 of 44 START sql dynamic_table model dl_gold.fact_holdings ................... [RUN]\n",
      "\u001b[0m21:27:22  41 of 44 OK created sql dynamic_table model dl_gold.fact_watches ............... [\u001b[32mSUCCESS 1\u001b[0m in 11.50s]\n",
      "\u001b[0m21:27:23  36 of 44 OK created sql dynamic_table model dl_gold.fact_market_history ........ [\u001b[32mSUCCESS 1\u001b[0m in 24.05s]\n",
      "\u001b[0m21:27:23  40 of 44 OK created sql dynamic_table model dl_gold.fact_cash_balances ......... [\u001b[32mSUCCESS 1\u001b[0m in 18.23s]\n",
      "\u001b[0m21:27:28  44 of 44 OK created sql dynamic_table model dl_gold.fact_holdings .............. [\u001b[32mSUCCESS 1\u001b[0m in 6.14s]\n",
      "\u001b[0m21:27:29  43 of 44 OK created sql dynamic_table model dl_gold.fact_trade ................. [\u001b[32mSUCCESS 1\u001b[0m in 9.24s]\n",
      "\u001b[0m21:27:29  \n",
      "\u001b[0m21:27:29  Finished running 44 dynamic_table models in 0 hours 0 minutes and 46.08 seconds (46.08s).\n",
      "\u001b[0m21:27:29  \n",
      "\u001b[0m21:27:29  \u001b[32mCompleted successfully\u001b[0m\n",
      "\u001b[0m21:27:29  \n",
      "\u001b[0m21:27:29  Done. PASS=44 WARN=0 ERROR=0 SKIP=0 TOTAL=44\n"
     ]
    }
   ],
   "source": [
    "!dbt build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5c05ca-a924-4549-ba19-d5fa61df5434",
   "metadata": {},
   "source": [
    "Click this link to open results:\n",
    "\n",
    "[Snowflake UI](https://app.snowflake.com/cxmdykz/hib36835/#/data/databases/TPCDI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb79852",
   "metadata": {},
   "source": [
    "### dbt also has Tests.\n",
    "\n",
    "We can run them when we create the Dynamic Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a62811a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m21:28:43  Running with dbt=1.7.2\n",
      "\u001b[0m21:28:44  Registered adapter: snowflake=1.7.0\n",
      "\u001b[0m21:28:44  Found 45 models, 17 sources, 0 exposures, 0 metrics, 544 macros, 0 groups, 0 semantic models\n",
      "\u001b[0m21:28:44  \n",
      "\u001b[0m21:28:45  Concurrency: 20 threads (target='dev')\n",
      "\u001b[0m21:28:45  \n",
      "\u001b[0m21:28:45  1 of 1 START sql dynamic_table model dl_gold.fact_trade ........................ [RUN]\n",
      "\u001b[0m21:28:48  1 of 1 OK created sql dynamic_table model dl_gold.fact_trade ................... [\u001b[32mSUCCESS 1\u001b[0m in 2.30s]\n",
      "\u001b[0m21:28:48  \n",
      "\u001b[0m21:28:48  Finished running 1 dynamic_table model in 0 hours 0 minutes and 3.74 seconds (3.74s).\n",
      "\u001b[0m21:28:48  \n",
      "\u001b[0m21:28:48  \u001b[32mCompleted successfully\u001b[0m\n",
      "\u001b[0m21:28:48  \n",
      "\u001b[0m21:28:48  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1\n"
     ]
    }
   ],
   "source": [
    "!dbt build --select fact_trade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d564eded",
   "metadata": {},
   "source": [
    "# Or we can schedule them to run periodically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf40309e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m21:29:25  Running with dbt=1.7.2\n",
      "\u001b[0m21:29:25  Registered adapter: snowflake=1.7.0\n",
      "\u001b[0m21:29:25  Found 45 models, 1 test, 17 sources, 0 exposures, 0 metrics, 544 macros, 0 groups, 0 semantic models\n",
      "\u001b[0m21:29:25  \n",
      "\u001b[0m21:29:26  Concurrency: 20 threads (target='dev')\n",
      "\u001b[0m21:29:26  \n",
      "\u001b[0m21:29:26  1 of 1 START test fact_trade__unique_trade ..................................... [RUN]\n",
      "\u001b[0m21:29:27  1 of 1 PASS fact_trade__unique_trade ........................................... [\u001b[32mPASS\u001b[0m in 1.39s]\n",
      "\u001b[0m21:29:27  \n",
      "\u001b[0m21:29:27  Finished running 1 test in 0 hours 0 minutes and 2.03 seconds (2.03s).\n",
      "\u001b[0m21:29:27  \n",
      "\u001b[0m21:29:27  \u001b[32mCompleted successfully\u001b[0m\n",
      "\u001b[0m21:29:27  \n",
      "\u001b[0m21:29:27  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1\n"
     ]
    }
   ],
   "source": [
    "!dbt test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3f442b",
   "metadata": {},
   "source": [
    "# More than just a scheduler.\n",
    "\n",
    "1. Cloud development environment for those that prefer it.\n",
    "1. CI/CD workflows for promoting Dynamic Table changes into Production.\n",
    "1. Perhaps there's promise in the Semantic Layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22101a49",
   "metadata": {},
   "source": [
    "# Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c6a912a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema dl_gold dropped.\n",
      "Schema dl_silver dropped.\n",
      "Schema dl_bronze dropped.\n",
      "Schema dl_work dropped.\n"
     ]
    }
   ],
   "source": [
    "!python tpcdi.py drop-schema --schema dl_gold\n",
    "!python tpcdi.py drop-schema --schema dl_silver\n",
    "!python tpcdi.py drop-schema --schema dl_bronze\n",
    "!python tpcdi.py drop-schema --schema dl_work"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
