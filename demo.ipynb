{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c989f41",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Title](images/title-page.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90ad24f-5035-4c5d-81e4-a81d9dff1e9a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Title](images/title-qr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed161285-5c6c-41de-a4ad-685a5de5ba0e",
   "metadata": {},
   "source": [
    "### What is the TPC?\n",
    "The TPC is a non-profit corporation focused on developing data-centric benchmark standards and disseminating objective, verifiable data to the industry.\n",
    "\n",
    "### What is TPC-DI?\n",
    "The TPC-DI benchmark combines and transforms data extracted from an On-Line Transaction Processing (OTLP) system along with other sources of data, and loads it into a data warehouse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a9e518-484a-4f18-80d4-4ae43c72312a",
   "metadata": {},
   "source": [
    "![ETL Diagram](images/tpc-di-etl-diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TPC-DI provides `DIGen.jar` to generate the source files.\n",
    "\n",
    "The JAR is dated and requires a 1.8 JDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: DIGen\n",
      " -h                   print this message\n",
      " -jvm <JVM options>   JVM options. E.g. -jvm \"-Xms1g -Xmx2g\"\n",
      " -o <directory>       Specify output directory.  Default is output.\n",
      " -sf <sf>             Scale factor.  Default value is 5. (range: 3 -\n",
      "                      2147483647\n",
      " -v                   print DIGen version\n"
     ]
    }
   ],
   "source": [
    "!jenv local 1.8\n",
    "!java -jar ~/dev/Tools/DIGen.jar --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/stewartbryson/dev/tpcdi-output\n",
      "########################################################################################################################\n",
      "                                                  PDGF v2.5_#1343_b4177\n",
      "                                            Parallel Data Generation Framework\n",
      "                (c)bankmark UG (haftungsbeschraenkt), Frank M., Danisch M., Rabl T. http://www.bankmark.de\n",
      "########################################################################################################################\n",
      "                                                   License information\n",
      "                            The Software is provided to you as part of the TPC Benchmark DI. \n",
      " When using this software you must agree to the license provided in LICENSE.TXT of this package. Use is restricted to TPC\n",
      "DI benchmarking purposes as specified in LICENSE.TXT. If you would like to use the software for other purposes, you must\n",
      "contact bankmark UG (haftungsbeschraenkt) (http://www.bankmark.de) to purchase a fully licensed copy of the Software.\n",
      "########################################################################################################################\n",
      "for a command overview start with commandline parameter: -help\n",
      "or type \"help\" in the built in shell: PDGF:> \n",
      "\n",
      "Set closeWhenDone from: false to: true\n",
      "Set project main scale factor from -notSet- to 5000.0\n",
      "Set default output path to:\"/Users/stewartbryson/dev/tpcdi-output/\"\n",
      "Loading configuration files ...\n",
      "23: XML <property name=\"SF\">5000.0 was already defined in config file or is manually overridden by a user set commandline argument. Currently assigned value: '5000.0' and will remain unchanged at this value\n",
      "Registered Generation event listner: tpc.di.output.AuditTotalRecordsSummaryWriter\n",
      "Loading successful.\n",
      "All required configuration files are loaded. You may start the generation process.\n",
      "Initializing system...\n",
      "Node 1 Worker count was not specified. Detected 8 available processors and start now same amount of workers\n",
      "FinWireFinBlackBox.initialize() LAST UPDATE ID: 202\n",
      "DailyMarketBlackBox.initialize() LAST UPDATE ID: 733\n",
      "initializing WatchHistoryBlackBox of table: 'WatchHistory'... done\n",
      "Cloning data structures for parallelization...\n",
      "Clone time 0h:00m:00s:153ms\n",
      "initialized 0h:00m:00s:333ms\n",
      "Starting data generation proccess...\n",
      "Startuptime: 0h:00m:00s:976ms\n",
      "FileChannelProvider is: pdgf.util.caching.fileWriter.OutputFileWriter$DefaultFileChannelProvider\n",
      "\n",
      "generating 1/16 \"StatusType\"\t  rows: 1-6 of 6\n",
      "\n",
      "PDGF:> finished  1/16 \"StatusType\"\t  in: 0h:00m:00s:008ms total size: 3.6 KiB average speed: 454.7 KiB/s\n",
      "\n",
      "generating 2/16 \"TaxRate\"\t  rows: 1-320 of 320\n",
      "finished  2/16 \"TaxRate\"\t  in: 0h:00m:00s:005ms total size: 16.7 KiB average speed: 3.3 MiB/s\n",
      "\n",
      "generating 3/16 \"Date\"\t  rows: 1-25933 of 25933\n",
      "finished  3/16 \"Date\"\t  in: 0h:00m:00s:416ms total size: 3.3 MiB average speed: 8.0 MiB/s\n",
      "\n",
      "generating 4/16 \"Time\"\t  rows: 1-86400 of 86400\n",
      "finished  4/16 \"Time\"\t  in: 0h:00m:00s:127ms total size: 4.6 MiB average speed: 35.9 MiB/s\n",
      "\n",
      "generating 5/16 \"BatchDate\"\t  update: historical\n",
      "finished  5/16 \"BatchDate\"\t  in: 0h:00m:00s:004ms total size: 88 B average speed: 21.5 KiB/s\n",
      "\n",
      "generating 6/16 \"HR\"\t  rows: 1-25000 of 25000\n",
      "finished  6/16 \"HR\"\t  in: 0h:00m:00s:048ms total size: 1.9 MiB average speed: 40.1 MiB/s\n",
      "\n",
      "generating 7/16 \"CustomerMgmt\"\t  update: historical\n",
      "finished  7/16 \"CustomerMgmt\"\t  in: 0h:00m:00s:399ms total size: 14.9 MiB average speed: 37.3 MiB/s\n",
      "\n",
      "generating 8/16 \"Customer\"\t  update: 431/432\n",
      "finished  8/16 \"Customer\"\t  in: 0h:00m:00s:005ms total size: 10.6 KiB average speed: 2.1 MiB/s\n",
      "\n",
      "generating 9/16 \"Account\"\t  update: 431/432\n",
      "finished  9/16 \"Account\"\t  in: 0h:00m:00s:003ms total size: 7.2 KiB average speed: 2.3 MiB/s\n",
      "\n",
      "generating 10/16 \"Prospect\"\t  update: historical\n",
      "finished  10/16 \"Prospect\"\t  in: 0h:00m:00s:194ms total size: 14.9 MiB average speed: 76.7 MiB/s\n",
      "\n",
      "generating 11/16 \"Industry\"\t  rows: 1-102 of 102\n",
      "finished  11/16 \"Industry\"\t  in: 0h:00m:00s:002ms total size: 2.7 KiB average speed: 1.3 MiB/s\n",
      "\n",
      "generating 12/16 \"FINWIRE\"\t  update: historical\n",
      "finished  12/16 \"FINWIRE\"\t  in: 0h:00m:00s:526ms total size: 44.2 MiB average speed: 84.0 MiB/s\n",
      "\n",
      "generating 13/16 \"DailyMarket\"\t  update: historical\n",
      "finished  13/16 \"DailyMarket\"\t  in: 0h:00m:01s:232ms total size: 136.1 MiB average speed: 110.5 MiB/s\n",
      "\n",
      "generating 14/16 \"WatchHistory\"\t  update: historical\n",
      "finished  14/16 \"WatchHistory\"\t  in: 0h:00m:00s:675ms total size: 66.9 MiB average speed: 99.1 MiB/s\n",
      "\n",
      "generating 15/16 \"TradeSource\"\t  update: historical\n",
      "finished  15/16 \"TradeSource\"\t  in: 0h:00m:02s:060ms total size: 177.0 MiB average speed: 85.9 MiB/s\n",
      "\n",
      "generating 16/16 \"TradeType\"\t  rows: 1-5 of 5\n",
      "All work done\n",
      "Data generation finished successfully\n",
      "AuditTotalRecordsSummaryWriter - TotalRecords for Batch1: 7804509\n",
      "AuditTotalRecordsSummaryWriter - TotalRecords for Batch2: 33380\n",
      "AuditTotalRecordsSummaryWriter - TotalRecords for Batch3: 33455\n",
      "AuditTotalRecordsSummaryWriter - TotalRecords all Batches: 7871344 1373947.29 records/second\n",
      "Statistics  \n",
      "=========\n",
      "Overall time\t0h:00m:05s:728ms\n",
      "Generated\t463.9 MiB\n",
      "Speed\t\t81.0 MiB/s\n",
      "\n",
      "DIGen completed successfully.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ~/dev/tpcdi-output\n",
    "!mkdir -p ~/dev/tpcdi-output\n",
    "!cd ~/dev/Tools && java -jar ~/dev/Tools/DIGen.jar -o ~/dev/tpcdi-output -sf 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The GitHub repository has a prebuilt CLI for easily loading the files.\n",
    "### https://github.com/stewartbryson/dbt-tpcdi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m                                                                                \u001b[0m\n",
      "\u001b[1m \u001b[0m\u001b[1;33mUsage: \u001b[0m\u001b[1mtpcdi.py [OPTIONS] COMMAND [ARGS]...\u001b[0m\u001b[1m                                   \u001b[0m\u001b[1m \u001b[0m\n",
      "\u001b[1m                                                                                \u001b[0m\n",
      " A utility for loading TPC-DI generated files into Snowflake.                   \n",
      "                                                                                \n",
      "\u001b[2m╭─\u001b[0m\u001b[2m Options \u001b[0m\u001b[2m───────────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "\u001b[2m│\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-install\u001b[0m\u001b[1;36m-completion\u001b[0m        \u001b[1;2;33m[\u001b[0m\u001b[1;33mbash\u001b[0m\u001b[1;2;33m|\u001b[0m\u001b[1;33mzsh\u001b[0m\u001b[1;2;33m|\u001b[0m\u001b[1;33mfish\u001b[0m\u001b[1;2;33m|\u001b[0m\u001b[1;33mpowershe\u001b[0m  Install completion for  \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                             \u001b[1;33mll\u001b[0m\u001b[1;2;33m|\u001b[0m\u001b[1;33mpwsh\u001b[0m\u001b[1;2;33m]\u001b[0m\u001b[1;33m               \u001b[0m  the specified shell.    \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                      \u001b[2m[default: None]        \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-show\u001b[0m\u001b[1;36m-completion\u001b[0m           \u001b[1;2;33m[\u001b[0m\u001b[1;33mbash\u001b[0m\u001b[1;2;33m|\u001b[0m\u001b[1;33mzsh\u001b[0m\u001b[1;2;33m|\u001b[0m\u001b[1;33mfish\u001b[0m\u001b[1;2;33m|\u001b[0m\u001b[1;33mpowershe\u001b[0m  Show completion for the \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                             \u001b[1;33mll\u001b[0m\u001b[1;2;33m|\u001b[0m\u001b[1;33mpwsh\u001b[0m\u001b[1;2;33m]\u001b[0m\u001b[1;33m               \u001b[0m  specified shell, to     \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                      copy it or customize    \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                      the installation.       \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                      \u001b[2m[default: None]        \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-help\u001b[0m                      \u001b[1;33m                       \u001b[0m  Show this message and   \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                      exit.                   \u001b[2m│\u001b[0m\n",
      "\u001b[2m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\u001b[2m╭─\u001b[0m\u001b[2m Commands \u001b[0m\u001b[2m──────────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "\u001b[2m│\u001b[0m \u001b[1;36mdrop-schema   \u001b[0m\u001b[1;36m \u001b[0m DROP a schema. Useful for cleaning up after a demo.          \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m \u001b[1;36mdrop-stage    \u001b[0m\u001b[1;36m \u001b[0m DROP the stage. Useful when all the data has been            \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m \u001b[1;36m               \u001b[0m successfully loaded.                                         \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m \u001b[1;36mprocess-files \u001b[0m\u001b[1;36m \u001b[0m Upload a file or files into the stage and build the          \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m \u001b[1;36m               \u001b[0m dependent tables.                                            \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m \u001b[1;36mrecreate-stage\u001b[0m\u001b[1;36m \u001b[0m CREATE or REPLACE the stage. Mostly useful while developing  \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m \u001b[1;36m               \u001b[0m this utility.                                                \u001b[2m│\u001b[0m\n",
      "\u001b[2m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python tpcdi.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m                                                                                \u001b[0m\n",
      "\u001b[1m \u001b[0m\u001b[1;33mUsage: \u001b[0m\u001b[1mtpcdi.py process-files [OPTIONS]\u001b[0m\u001b[1m                                       \u001b[0m\u001b[1m \u001b[0m\n",
      "\u001b[1m                                                                                \u001b[0m\n",
      " Upload a file or files into the stage and build the dependent tables.          \n",
      "                                                                                \n",
      "\u001b[2m╭─\u001b[0m\u001b[2m Options \u001b[0m\u001b[2m───────────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "\u001b[2m│\u001b[0m \u001b[31m*\u001b[0m  \u001b[1;36m-\u001b[0m\u001b[1;36m-output\u001b[0m\u001b[1;36m-directory\u001b[0m                        \u001b[1;33mTEXT   \u001b[0m  The output directory   \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       from the TPC-DI        \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       DIGen.jar execution.   \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2m[default: None]       \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2;31m[required]            \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-file\u001b[0m\u001b[1;36m-name\u001b[0m                               \u001b[1;33mTEXT   \u001b[0m  The TPC-DI file name   \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       to upload and process. \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       Pass value 'FINWIRE'   \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       to process all of the  \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       financial wire files.  \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2m[default: all]        \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-stage\u001b[0m                                   \u001b[1;33mTEXT   \u001b[0m  The stage name to      \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       upload to, without     \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       specifying '@'.        \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2m[default: tpcdi]      \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-batch\u001b[0m                                   \u001b[1;33mINTEGER\u001b[0m  The TPC-DI batch       \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       number to process.     \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       Currently only         \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       supports the default   \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       of '1'.                \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2m[default: 1]          \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-overwrite\u001b[0m           \u001b[1;35m-\u001b[0m\u001b[1;35m-no\u001b[0m\u001b[1;35m-overwrite\u001b[0m      \u001b[1;33m       \u001b[0m  Overwrite the file     \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       even if it exists?     \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2m[default:             \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2mno-overwrite]         \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-skip\u001b[0m\u001b[1;36m-upload\u001b[0m         \u001b[1;35m-\u001b[0m\u001b[1;35m-no\u001b[0m\u001b[1;35m-skip-upload\u001b[0m    \u001b[1;33m       \u001b[0m  Skip uploading the     \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       files?                 \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2m[default:             \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2mno-skip-upload]       \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-show\u001b[0m                \u001b[1;35m-\u001b[0m\u001b[1;35m-no\u001b[0m\u001b[1;35m-show\u001b[0m           \u001b[1;33m       \u001b[0m  Show the DataFrame     \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       instead of saving it   \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       as a table? This was   \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       useful during          \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       development.           \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       \u001b[2m[default: no-show]    \u001b[0m \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-help\u001b[0m                                    \u001b[1;33m       \u001b[0m  Show this message and  \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                                                       exit.                  \u001b[2m│\u001b[0m\n",
      "\u001b[2m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python tpcdi.py process-files --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File DailyMarket.txt: SKIPPED\n",
      "----------------------------------------------------------------------------------\n",
      "|\"DM_DATE\"   |\"DM_S_SYMB\"      |\"DM_CLOSE\"  |\"DM_HIGH\"  |\"DM_LOW\"  |\"DM_VOL\"     |\n",
      "----------------------------------------------------------------------------------\n",
      "|2015-07-06  |AAAAAAAAAAAAERN  |242.93      |284.42     |185.08    |111904727.0  |\n",
      "|2015-07-06  |AAAAAAAAAAAAEYJ  |445.46      |522.3      |386.48    |78849320.0   |\n",
      "|2015-07-06  |AAAAAAAAAAAAEVC  |910.59      |1148.89    |723.37    |807515829.0  |\n",
      "|2015-07-06  |AAAAAAAAAAAACEZ  |647.07      |756.68     |473.3     |693226268.0  |\n",
      "|2015-07-06  |AAAAAAAAAAAADOY  |385.01      |564.67     |295.63    |34628570.0   |\n",
      "|2015-07-06  |AAAAAAAAAAAADSD  |28.01       |34.59      |23.66     |47032973.0   |\n",
      "|2015-07-06  |AAAAAAAAAAAAELH  |186.85      |249.13     |170.26    |79305649.0   |\n",
      "|2015-07-06  |AAAAAAAAAAAAAXX  |880.03      |990.35     |727.51    |353491380.0  |\n",
      "|2015-07-06  |AAAAAAAAAAAABVO  |911.31      |1143.78    |695.46    |868269480.0  |\n",
      "|2015-07-06  |AAAAAAAAAAAADBL  |23.44       |27.08      |13.28     |441304717.0  |\n",
      "----------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python tpcdi.py process-files --output-directory ~/dev/tpcdi-output --file-name DailyMarket.txt --show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get nothing else from this video, know that there's an easy way to load this dataset into Snowflake.\n",
    "\n",
    "But I also wanted to show some interesting approaches using Snowpark.\n",
    "\n",
    "All of the code samples below are snippets from the CLI with abstractions removed.\n",
    "\n",
    "We start with a `credentials.json` file to store our Snowflake credentials. Something like this:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"account\": \"myaccount\",\n",
    "    \"user\": \"myuser\",\n",
    "    \"password\": \"mypassword\",\n",
    "    \"role\": \"myrole\",\n",
    "    \"warehouse\": \"stewart_dev\",\n",
    "    \"database\": \"tpc_di\",\n",
    "    \"schema\": \"digen\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can make a connection to Snowflake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, json\n",
    "from snowflake.snowpark import Session, DataFrame\n",
    "from snowflake.snowpark.types import *\n",
    "from snowflake.snowpark.functions import *\n",
    "from pathlib import Path\n",
    "\n",
    "# Read the credentials.json file\n",
    "with open(\"credentials.json\") as jsonfile:\n",
    "    credentials_dict = json.load(jsonfile)\n",
    "\n",
    "# build the session\n",
    "session = (\n",
    "    Session\n",
    "    .builder\n",
    "    .configs(credentials_dict)\n",
    "    .create()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the files generated by `DIGen.jar` are pipe-separated files, very similar to CSV files.\n",
    "\n",
    "These are very simple to handle. First let's upload the file to a stage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File DailyMarket.txt: SKIPPED\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "source_path = '/Users/stewartbryson/dev/tpcdi-output/Batch1'\n",
    "stage_path = \"@tpcdi/Batch1\"\n",
    "\n",
    "# Put the file\n",
    "put_result = (\n",
    "    session\n",
    "    .file\n",
    "    .put(\n",
    "        f\"{source_path}/DailyMarket.txt\",\n",
    "        f\"{stage_path}/DailyMarket.txt\",\n",
    "        parallel=4,\n",
    "        auto_compress=True,\n",
    "    )\n",
    ")\n",
    "for result in put_result:\n",
    "    print(f\"File {result.source}: {result.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we'll create a table from that file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------\n",
      "|\"DM_DATE\"   |\"DM_S_SYMB\"      |\"DM_CLOSE\"  |\"DM_HIGH\"  |\"DM_LOW\"  |\"DM_VOL\"     |\n",
      "----------------------------------------------------------------------------------\n",
      "|2016-12-18  |AAAAAAAAAAAABZF  |961.07      |1394.14    |847.64    |709969048.0  |\n",
      "|2016-12-18  |AAAAAAAAAAAABGY  |134.65      |173.1      |106.55    |122085128.0  |\n",
      "|2016-12-18  |AAAAAAAAAAAACFY  |497.2       |741.06     |427.71    |8263059.0    |\n",
      "|2016-12-18  |AAAAAAAAAAAACJW  |697.83      |988.37     |630.96    |576146934.0  |\n",
      "|2016-12-18  |AAAAAAAAAAAAELN  |512.4       |699.93     |508.04    |532344015.0  |\n",
      "|2016-12-18  |AAAAAAAAAAAADQU  |115.56      |146.54     |71.32     |808265496.0  |\n",
      "|2016-12-18  |AAAAAAAAAAAABSG  |38.99       |39.65      |29.36     |696226368.0  |\n",
      "|2016-12-18  |AAAAAAAAAAAAAOO  |640.01      |905.5      |581.14    |828920058.0  |\n",
      "|2016-12-18  |AAAAAAAAAAAACYZ  |396.78      |536.03     |233.16    |713253731.0  |\n",
      "|2016-12-18  |AAAAAAAAAAAABJF  |531.56      |706.06     |504.6     |629992002.0  |\n",
      "----------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the schema\n",
    "schema = StructType([\n",
    "                StructField(\"DM_DATE\", DateType(), False),\n",
    "                StructField(\"DM_S_SYMB\", StringType(), False),\n",
    "                StructField(\"DM_CLOSE\", FloatType(), False),\n",
    "                StructField(\"DM_HIGH\", FloatType(), False),\n",
    "                StructField(\"DM_LOW\", FloatType(), False),\n",
    "                StructField(\"DM_VOL\", FloatType(), False),\n",
    "        ])\n",
    "\n",
    "# create a table from a DataFrame\n",
    "df = (\n",
    "    session\n",
    "    .read\n",
    "    .schema(schema)\n",
    "    .option(\"field_delimiter\", '|')\n",
    "    .csv(f\"{stage_path}/DailyMarket.txt\")\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .save_as_table('daily_market')\n",
    ")\n",
    "\n",
    "# show the table\n",
    "df = (\n",
    "    session \n",
    "    .table('daily_market') \n",
    "    .show()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DIGen.jar` utility generates a series of \"finwire\" files.\n",
    "\n",
    "These files represent market history over time.\n",
    "\n",
    "They are fixed-width, multi-format files.\n",
    "For instance, the following sample has one of each type of record: `FIN`, `SEC`, and `CMP`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20151230-152248FIN201542015100120151230    4880880089.63    2473473307.30        4.82        4.42        0.51     200321223.47  139284472514.02    9402305760.19    512872010    5597926720000001595\n",
      "20151230-152511SECAAAAAAAAAAAAKVDPREF_AACTVDJBJXyQHLBvn EEOGAOvUNgL XwrOxQUBMrgPv                                AMEX  982113436    1903022619730704        1.200000000254\n",
      "20151230-163207CMPWWfcsOHprIDIUsPfRLrcLPlxaQ                                  0000004432ACTVMCA   1873092521088 Vessey Crescent                                                                                                                                           M5D 1Z1     Winnipeg                 AL                  United States of AmericaMoreno                                        rlRIDCNz dVGrEzomCXIvZVZzFzxCzbGYIEbAXJMJlsYUQEV"
     ]
    }
   ],
   "source": [
    "!cat devrel/multi-record.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by uploading all the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File FINWIRE2001Q3: SKIPPED\n",
      "File FINWIRE2001Q4: SKIPPED\n",
      "File FINWIRE1997Q4: SKIPPED\n",
      "File FINWIRE1970Q3: SKIPPED\n",
      "File FINWIRE1997Q3: SKIPPED\n",
      "File FINWIRE1970Q4: SKIPPED\n",
      "File FINWIRE1999Q2: SKIPPED\n",
      "File FINWIRE1991Q1: SKIPPED\n",
      "File FINWIRE2005Q2: SKIPPED\n",
      "File FINWIRE1976Q1: SKIPPED\n",
      "File FINWIRE1993Q2: SKIPPED\n",
      "File FINWIRE1974Q2: SKIPPED\n",
      "File FINWIRE2007Q1: SKIPPED\n",
      "File FINWIRE1997Q2: SKIPPED\n",
      "File FINWIRE1978Q1: SKIPPED\n",
      "File FINWIRE1970Q2: SKIPPED\n",
      "File FINWIRE2003Q1: SKIPPED\n",
      "File FINWIRE1995Q1: SKIPPED\n",
      "File FINWIRE2009Q1: SKIPPED\n",
      "File FINWIRE2001Q2: SKIPPED\n",
      "File FINWIRE1972Q1: SKIPPED\n",
      "File FINWIRE1974Q3: SKIPPED\n",
      "File FINWIRE1993Q4: SKIPPED\n",
      "File FINWIRE1974Q4: SKIPPED\n",
      "File FINWIRE1993Q3: SKIPPED\n",
      "File FINWIRE1999Q4: SKIPPED\n",
      "File FINWIRE2005Q3: SKIPPED\n",
      "File FINWIRE2005Q4: SKIPPED\n",
      "File FINWIRE1999Q3: SKIPPED\n",
      "File FINWIRE1987Q2: SKIPPED\n",
      "File FINWIRE1968Q1: SKIPPED\n",
      "File FINWIRE2013Q1: SKIPPED\n",
      "File FINWIRE1985Q1: SKIPPED\n",
      "File FINWIRE2011Q2: SKIPPED\n",
      "File FINWIRE1983Q4: SKIPPED\n",
      "File FINWIRE1983Q3: SKIPPED\n",
      "File FINWIRE1989Q4: SKIPPED\n",
      "File FINWIRE2015Q3: SKIPPED\n",
      "File FINWIRE2015Q4: SKIPPED\n",
      "File FINWIRE1989Q3: SKIPPED\n",
      "File FINWIRE2011Q3: SKIPPED\n",
      "File FINWIRE2011Q4: SKIPPED\n",
      "File FINWIRE1987Q4: SKIPPED\n",
      "File FINWIRE1987Q3: SKIPPED\n",
      "File FINWIRE1989Q2: SKIPPED\n",
      "File FINWIRE1981Q1: SKIPPED\n",
      "File FINWIRE2015Q2: SKIPPED\n",
      "File FINWIRE1983Q2: SKIPPED\n",
      "File FINWIRE2017Q1: SKIPPED\n",
      "File FINWIRE1992Q1: SKIPPED\n",
      "File FINWIRE1975Q1: SKIPPED\n",
      "File FINWIRE2006Q2: SKIPPED\n",
      "File FINWIRE1990Q2: SKIPPED\n",
      "File FINWIRE1998Q1: SKIPPED\n",
      "File FINWIRE2004Q1: SKIPPED\n",
      "File FINWIRE1977Q2: SKIPPED\n",
      "File FINWIRE2002Q3: SKIPPED\n",
      "File FINWIRE1979Q3: SKIPPED\n",
      "File FINWIRE2002Q4: SKIPPED\n",
      "File FINWIRE1979Q4: SKIPPED\n",
      "File FINWIRE1973Q3: SKIPPED\n",
      "File FINWIRE2008Q3: SKIPPED\n",
      "File FINWIRE1994Q4: SKIPPED\n",
      "File FINWIRE1973Q4: SKIPPED\n",
      "File FINWIRE1994Q3: SKIPPED\n",
      "File FINWIRE2008Q4: SKIPPED\n",
      "File FINWIRE1990Q4: SKIPPED\n",
      "File FINWIRE1977Q3: SKIPPED\n",
      "File FINWIRE1990Q3: SKIPPED\n",
      "File FINWIRE1977Q4: SKIPPED\n",
      "File FINWIRE2006Q3: SKIPPED\n",
      "File FINWIRE2006Q4: SKIPPED\n",
      "File FINWIRE1994Q2: SKIPPED\n",
      "File FINWIRE2000Q1: SKIPPED\n",
      "File FINWIRE1973Q2: SKIPPED\n",
      "File FINWIRE2008Q2: SKIPPED\n",
      "File FINWIRE1996Q1: SKIPPED\n",
      "File FINWIRE1971Q1: SKIPPED\n",
      "File FINWIRE2002Q2: SKIPPED\n",
      "File FINWIRE1979Q2: SKIPPED\n",
      "File FINWIRE1980Q4: SKIPPED\n",
      "File FINWIRE1967Q3: SKIPPED\n",
      "File FINWIRE1980Q3: SKIPPED\n",
      "File FINWIRE1967Q4: SKIPPED\n",
      "File FINWIRE2016Q3: SKIPPED\n",
      "File FINWIRE2016Q4: SKIPPED\n",
      "File FINWIRE1984Q2: SKIPPED\n",
      "File FINWIRE2010Q1: SKIPPED\n",
      "File FINWIRE1986Q1: SKIPPED\n",
      "File FINWIRE2012Q2: SKIPPED\n",
      "File FINWIRE1969Q2: SKIPPED\n",
      "File FINWIRE1982Q1: SKIPPED\n",
      "File FINWIRE2016Q2: SKIPPED\n",
      "File FINWIRE1980Q2: SKIPPED\n",
      "File FINWIRE1988Q1: SKIPPED\n",
      "File FINWIRE2014Q1: SKIPPED\n",
      "File FINWIRE1967Q2: SKIPPED\n",
      "File FINWIRE2012Q3: SKIPPED\n",
      "File FINWIRE1969Q3: SKIPPED\n",
      "File FINWIRE2012Q4: SKIPPED\n",
      "File FINWIRE1969Q4: SKIPPED\n",
      "File FINWIRE1984Q4: SKIPPED\n",
      "File FINWIRE1984Q3: SKIPPED\n",
      "File FINWIRE2005Q1: SKIPPED\n",
      "File FINWIRE1976Q2: SKIPPED\n",
      "File FINWIRE1999Q1: SKIPPED\n",
      "File FINWIRE1991Q2: SKIPPED\n",
      "File FINWIRE1974Q1: SKIPPED\n",
      "File FINWIRE2007Q2: SKIPPED\n",
      "File FINWIRE1993Q1: SKIPPED\n",
      "File FINWIRE2009Q4: SKIPPED\n",
      "File FINWIRE1995Q3: SKIPPED\n",
      "File FINWIRE1972Q4: SKIPPED\n",
      "File FINWIRE1995Q4: SKIPPED\n",
      "File FINWIRE2009Q3: SKIPPED\n",
      "File FINWIRE1972Q3: SKIPPED\n",
      "File FINWIRE1978Q4: SKIPPED\n",
      "File FINWIRE2003Q4: SKIPPED\n",
      "File FINWIRE1978Q3: SKIPPED\n",
      "File FINWIRE2003Q3: SKIPPED\n",
      "File FINWIRE2007Q4: SKIPPED\n",
      "File FINWIRE2007Q3: SKIPPED\n",
      "File FINWIRE1976Q4: SKIPPED\n",
      "File FINWIRE1991Q3: SKIPPED\n",
      "File FINWIRE1976Q3: SKIPPED\n",
      "File FINWIRE1991Q4: SKIPPED\n",
      "File FINWIRE1978Q2: SKIPPED\n",
      "File FINWIRE1970Q1: SKIPPED\n",
      "File FINWIRE2003Q2: SKIPPED\n",
      "File FINWIRE1997Q1: SKIPPED\n",
      "File FINWIRE2009Q2: SKIPPED\n",
      "File FINWIRE2001Q1: SKIPPED\n",
      "File FINWIRE1972Q2: SKIPPED\n",
      "File FINWIRE1995Q2: SKIPPED\n",
      "File FINWIRE2017Q3: SKIPPED\n",
      "File FINWIRE1981Q3: SKIPPED\n",
      "File FINWIRE1981Q4: SKIPPED\n",
      "File FINWIRE1968Q2: SKIPPED\n",
      "File FINWIRE2013Q2: SKIPPED\n",
      "File FINWIRE1987Q1: SKIPPED\n",
      "File FINWIRE2011Q1: SKIPPED\n",
      "File FINWIRE1985Q2: SKIPPED\n",
      "File FINWIRE2015Q1: SKIPPED\n",
      "File FINWIRE1989Q1: SKIPPED\n",
      "File FINWIRE1981Q2: SKIPPED\n",
      "File FINWIRE2017Q2: SKIPPED\n",
      "File FINWIRE1983Q1: SKIPPED\n",
      "File FINWIRE1985Q3: SKIPPED\n",
      "File FINWIRE1985Q4: SKIPPED\n",
      "File FINWIRE1968Q4: SKIPPED\n",
      "File FINWIRE2013Q4: SKIPPED\n",
      "File FINWIRE1968Q3: SKIPPED\n",
      "File FINWIRE2013Q3: SKIPPED\n",
      "File FINWIRE1971Q4: SKIPPED\n",
      "File FINWIRE1996Q3: SKIPPED\n",
      "File FINWIRE1971Q3: SKIPPED\n",
      "File FINWIRE1996Q4: SKIPPED\n",
      "File FINWIRE2000Q4: SKIPPED\n",
      "File FINWIRE2000Q3: SKIPPED\n",
      "File FINWIRE1975Q2: SKIPPED\n",
      "File FINWIRE2006Q1: SKIPPED\n",
      "File FINWIRE1992Q2: SKIPPED\n",
      "File FINWIRE2004Q2: SKIPPED\n",
      "File FINWIRE1977Q1: SKIPPED\n",
      "File FINWIRE1990Q1: SKIPPED\n",
      "File FINWIRE1998Q2: SKIPPED\n",
      "File FINWIRE2000Q2: SKIPPED\n",
      "File FINWIRE1973Q1: SKIPPED\n",
      "File FINWIRE2008Q1: SKIPPED\n",
      "File FINWIRE1994Q1: SKIPPED\n",
      "File FINWIRE1971Q2: SKIPPED\n",
      "File FINWIRE2002Q1: SKIPPED\n",
      "File FINWIRE1979Q1: SKIPPED\n",
      "File FINWIRE1996Q2: SKIPPED\n",
      "File FINWIRE1998Q3: SKIPPED\n",
      "File FINWIRE2004Q4: SKIPPED\n",
      "File FINWIRE2004Q3: SKIPPED\n",
      "File FINWIRE1998Q4: SKIPPED\n",
      "File FINWIRE1992Q3: SKIPPED\n",
      "File FINWIRE1975Q4: SKIPPED\n",
      "File FINWIRE1992Q4: SKIPPED\n",
      "File FINWIRE1975Q3: SKIPPED\n",
      "File FINWIRE2010Q2: SKIPPED\n",
      "File FINWIRE1984Q1: SKIPPED\n",
      "File FINWIRE2012Q1: SKIPPED\n",
      "File FINWIRE1969Q1: SKIPPED\n",
      "File FINWIRE1986Q2: SKIPPED\n",
      "File FINWIRE1988Q3: SKIPPED\n",
      "File FINWIRE2014Q4: SKIPPED\n",
      "File FINWIRE2014Q3: SKIPPED\n",
      "File FINWIRE1988Q4: SKIPPED\n",
      "File FINWIRE1982Q3: SKIPPED\n",
      "File FINWIRE1982Q4: SKIPPED\n",
      "File FINWIRE1986Q3: SKIPPED\n",
      "File FINWIRE1986Q4: SKIPPED\n",
      "File FINWIRE2010Q4: SKIPPED\n",
      "File FINWIRE2010Q3: SKIPPED\n",
      "File FINWIRE2016Q1: SKIPPED\n",
      "File FINWIRE1982Q2: SKIPPED\n",
      "File FINWIRE2014Q2: SKIPPED\n",
      "File FINWIRE1967Q1: SKIPPED\n",
      "File FINWIRE1980Q1: SKIPPED\n",
      "File FINWIRE1988Q2: SKIPPED\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "stage_path = \"@tpcdi/Batch1/FINWIRE\"\n",
    "\n",
    "# glob the files\n",
    "pathlist = (\n",
    "    Path(source_path)\n",
    "    .glob(\"FINWIRE??????\")\n",
    ")\n",
    "\n",
    "for file in pathlist:\n",
    "    # put the file(s) in the stage\n",
    "    put_result = (\n",
    "        session \n",
    "        .file\n",
    "        .put(\n",
    "            str(file), \n",
    "            stage_path, \n",
    "            parallel=4, \n",
    "            auto_compress=True\n",
    "        )\n",
    "    )\n",
    "    for result in put_result:\n",
    "        print(f\"File {result.source}: {result.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CMP, SEC, and FIN records all have two fields in common, so we want to create a generic DataFrame that contains the shared logic and we’ll save that DataFrame as a Snowflake temporary table called FINWIRE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "|\"LINE\"                                              |\"PTS\"                |\"REC_TYPE\"  |\n",
      "-----------------------------------------------------------------------------------------\n",
      "|19670401-065923FIN196721967040119670401    9288...  |1967-04-01 06:59:23  |FIN         |\n",
      "|19670401-161220FIN196721967040119670401    6180...  |1967-04-01 16:12:20  |FIN         |\n",
      "|19670402-012108FIN196721967040119670402     818...  |1967-04-02 01:21:08  |FIN         |\n",
      "|19670402-140519FIN196721967040119670402    3590...  |1967-04-02 14:05:19  |FIN         |\n",
      "|19670403-051650FIN196721967040119670403    6457...  |1967-04-03 05:16:50  |FIN         |\n",
      "|19670403-194201FIN196721967040119670403    6692...  |1967-04-03 19:42:01  |FIN         |\n",
      "|19670404-011711FIN196721967040119670404    5352...  |1967-04-04 01:17:11  |FIN         |\n",
      "|19670404-023010FIN196721967040119670404    7901...  |1967-04-04 02:30:10  |FIN         |\n",
      "|19670404-072732FIN196721967040119670404    8417...  |1967-04-04 07:27:32  |FIN         |\n",
      "|19670404-134250FIN196721967040119670404    5765...  |1967-04-04 13:42:50  |FIN         |\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# These are fixed-width fields, so read the entire line in as \"line\"\n",
    "schema = StructType([\n",
    "        StructField(\"line\", StringType(), False),\n",
    "])\n",
    "\n",
    "# generic dataframe for all record types\n",
    "# create a temporary table\n",
    "# The delimiter '|' seems safer\n",
    "df = (\n",
    "    session\n",
    "    .read\n",
    "    .schema(schema)\n",
    "    .option('field_delimiter', '|')\n",
    "    .csv(stage_path)\n",
    "    .with_column(\n",
    "        'pts', \n",
    "        to_timestamp(\n",
    "            substring(col(\"line\"), lit(0), lit(15)), \n",
    "            lit(\"yyyymmdd-hhmiss\")\n",
    "        )\n",
    "    )\n",
    "    .with_column(\n",
    "        'rec_type', \n",
    "        substring(col(\"line\"), lit(16), lit(3))\n",
    "    )\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .save_as_table(\"finwire\", table_type=\"temporary\")\n",
    ")\n",
    "\n",
    "# let's see the table\n",
    "df = (\n",
    "    session \n",
    "    .table('finwire') \n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can create the three separate tables from this temporary table using `WITH_COLUMN` and `SUBSTRING`.\n",
    "\n",
    "I'll only show the Security table as an example, but the other two are done the same way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEC table created.\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"PTS\"                |\"SYMBOL\"         |\"ISSUE_TYPE\"  |\"STATUS\"  |\"NAME\"                                              |\"EX_ID\"  |\"SH_OUT\"       |\"FIRST_TRADE_DATE\"  |\"FIRST_EXCHANGE_DATE\"  |\"DIVIDEND\"    |\"CO_NAME_OR_CIK\"                                    |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|1968-06-12 02:43:03  |AAAAAAAAAAAAAJG  |COMMON        |ACTV      |rFALDSWBSGSnzzMwTwjF                           ...  |PCX      |792341095      |19230923            |19301212               |        0.68  |dGTSaPOJMHvtCCHelvrPOQXnY                      ...  |\n",
      "|1968-06-14 10:29:54  |AAAAAAAAAAAAAJF  |COMMON        |ACTV      |tZVXPNivYmcKiIoOwwGzwKftrcpUPDkCQKoKbPbBFvEcH  ...  |AMEX     |848522297      |18890530            |19210419               |        0.54  |nFkXCFIQQcAPOHRuYtieKkGSZpAdCmvxWPuheWUSLiFkN  ...  |\n",
      "|1968-06-14 17:01:23  |AAAAAAAAAAAAAJE  |COMMON        |ACTV      |UtoEIg aYYaIOZHqbaoiIfKAFeYAefmUjkCQrFFtSeJsFiB...  |NYSE     |506721656      |19300608            |18691015               |        1.30  |0000000072                                          |\n",
      "|1968-06-14 20:30:54  |AAAAAAAAAAAAAJD  |COMMON        |ACTV      |OStNwLwpIlLRvMVQEGigfSHHsYzqKWRpyXIXiAcOH      ...  |NASDAQ   |364968850      |19010826            |19661108               |        0.93  |dBBCsCzeivSxrOWJZkMbNfLitfJSVqvvAy             ...  |\n",
      "|1968-06-16 10:58:30  |AAAAAAAAAAAAAJC  |COMMON        |ACTV      |RtffDRwxjXdhGANMNfZRKFByDpnKfFHkBIPJtGOOJCDVINq...  |PCX      |643887645      |18750523            |19411123               |        0.45  |zScyndwxOcLUXIwtrdKPFPDeQiYudN                 ...  |\n",
      "|1968-06-17 06:24:16  |AAAAAAAAAAAAAJB  |COMMON        |ACTV      |bQiPAhBJXYqJnNhIugWOBQZRI                      ...  |NASDAQ   |769161945      |19180731            |19540313               |        0.41  |0000000077                                          |\n",
      "|1968-06-17 23:30:19  |AAAAAAAAAAAAAJA  |PREF_A        |ACTV      |KQNCmlNrCaKozrTtwxjFtXtOLUEymubHULanCRApTUOCOoN...  |AMEX     |608656022      |19561206            |18690708               |        2.44  |0000000014                                          |\n",
      "|1968-06-18 03:56:09  |AAAAAAAAAAAAAIZ  |COMMON        |ACTV      |wtERZLMKsSYbyScRwKWFhAKuuJRqFbETvejObbEQDSd ods...  |NYSE     |601651039      |18700414            |18980108               |        2.32  |0000000012                                          |\n",
      "|1968-06-18 06:05:36  |AAAAAAAAAAAAAIY  |COMMON        |ACTV      |FieMLbpaoNUcUBPjwgHlDZdQwGxzQfBIaUTXRhHGdHkX WI...  |PCX      |784709609      |18800601            |18690309               |        2.45  |0000000035                                          |\n",
      "|1968-06-19 12:29:40  |AAAAAAAAAAAAAGD  |COMMON        |INAC      |yaVsFhUzAcjyhMIjAQgqWRANniFatEH k              ...  |NASDAQ   |131790475      |19160607            |19220828               |        0.17  |0000000072                                          |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SEC record types\n",
    "table_name = 'sec'\n",
    "df = (\n",
    "    session\n",
    "    .table('finwire')\n",
    "    .where(col('rec_type') == 'SEC')\n",
    "    .withColumn(\n",
    "        'symbol', \n",
    "        substring(col(\"line\"), lit(19), lit(15))\n",
    "    )\n",
    "    .withColumn(\n",
    "        'issue_type', \n",
    "        substring(col(\"line\"), lit(34), lit(6))\n",
    "    )\n",
    "    .withColumn(\n",
    "        'status', \n",
    "        substring(col(\"line\"), lit(40), lit(4))\n",
    "    )\n",
    "    .withColumn(\n",
    "        'name', \n",
    "        substring(col(\"line\"), lit(44), lit(70))\n",
    "    )\n",
    "    .withColumn(\n",
    "        'ex_id', \n",
    "        substring(col(\"line\"), lit(114), lit(6))\n",
    "    )\n",
    "    .withColumn(\n",
    "        'sh_out', \n",
    "        substring(col(\"line\"), lit(120), lit(13))\n",
    "    )\n",
    "    .withColumn(\n",
    "        'first_trade_date', \n",
    "        substring(col(\"line\"), lit(133), lit(8))\n",
    "    )\n",
    "    .withColumn(\n",
    "        'first_exchange_date', \n",
    "        substring(col(\"line\"), lit(141), lit(8))\n",
    "    )\n",
    "    .withColumn(\n",
    "        'dividend', \n",
    "        substring(col(\"line\"), lit(149), lit(12))\n",
    "    )\n",
    "    .withColumn(\n",
    "        'co_name_or_cik', \n",
    "        substring(col(\"line\"), lit(161), lit(60))\n",
    "    )\n",
    "    .drop(col(\"line\"), col(\"rec_type\"))\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .save_as_table(table_name)\n",
    ")\n",
    "\n",
    "print(f\"{table_name.upper()} table created.\")\n",
    "\n",
    "# let's see the table\n",
    "df = (\n",
    "    session \n",
    "    .table('sec') \n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ETL Diagram](images/tpc-di-logical-model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442d9973-dcdb-491f-82d2-0a1ec2d133aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "# When we search on Google for \"dbt dynamic tables\":\n",
    "\n",
    "![Google Search](images/dbt-dynamic-tables.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73ac995-dcdf-4d7d-96d8-4f23eafc16c9",
   "metadata": {},
   "source": [
    "# Is it as simple as this?\n",
    "\n",
    "![Conflict](images/refresh-conflict.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e4236c-46da-4b50-aa37-225df6ff9f7f",
   "metadata": {},
   "source": [
    "# Remember, there's more to dbt than just scheduling refresh jobs. There's a DAG to consider.\n",
    "\n",
    "# Dynamic Tables need to be (re)created in the correct order. This can become very complex as the number of tables and dependencies increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b6de585-2299-4039-bce3-cf27ad5290d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m16:40:18  Running with dbt=1.6.6\n",
      "\u001b[0m16:40:18  Registered adapter: snowflake=1.6.4\n",
      "\u001b[0m16:40:18  Unable to do partial parsing because of a version mismatch\n",
      "\u001b[0m16:40:19  Found 45 models, 17 sources, 0 exposures, 0 metrics, 489 macros, 0 groups, 0 semantic models\n",
      "\u001b[0m16:40:19  \n",
      "\u001b[0m16:40:20  Concurrency: 20 threads (target='dev')\n",
      "\u001b[0m16:40:20  \n",
      "\u001b[0m16:40:20  Building catalog\n",
      "\u001b[0m16:40:26  Catalog written to /Users/stewartbryson/Source/dbt-tpcdi/target/catalog.json\n",
      "\u001b[0m16:40:27  Running with dbt=1.6.6\n",
      "Serving docs at 8080\n",
      "To access from your browser, navigate to: http://localhost:8080\n",
      "\n",
      "\n",
      "\n",
      "Press Ctrl+C to exit.\n",
      "127.0.0.1 - - [27/Nov/2023 11:40:28] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [27/Nov/2023 11:40:28] \"GET /manifest.json?cb=1701103228480 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [27/Nov/2023 11:40:28] \"GET /catalog.json?cb=1701103228480 HTTP/1.1\" 200 -\n",
      "^C\n",
      "\u001b[0m16:41:38  Encountered an error:\n",
      "\n",
      "\u001b[0m16:41:38  Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/tpcdi/lib/python3.8/site-packages/dbt/cli/requires.py\", line 87, in wrapper\n",
      "    result, success = func(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/tpcdi/lib/python3.8/site-packages/dbt/cli/requires.py\", line 72, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/tpcdi/lib/python3.8/site-packages/dbt/cli/requires.py\", line 143, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/tpcdi/lib/python3.8/site-packages/dbt/cli/requires.py\", line 172, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/tpcdi/lib/python3.8/site-packages/dbt/cli/requires.py\", line 219, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/tpcdi/lib/python3.8/site-packages/dbt/cli/main.py\", line 320, in docs_serve\n",
      "    results = task.run()\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/tpcdi/lib/python3.8/site-packages/dbt/task/serve.py\", line 28, in run\n",
      "    httpd.serve_forever()\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/tpcdi/lib/python3.8/socketserver.py\", line 232, in serve_forever\n",
      "    ready = selector.select(poll_interval)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/tpcdi/lib/python3.8/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!dbt docs generate\n",
    "!dbt docs serve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff43cb2d-3022-404a-aa5d-ccb1b8862492",
   "metadata": {},
   "source": [
    "# Let's take a look at a standard dbt project, using the TPC-DI dataset.\n",
    "\n",
    "# I'll just pull the `dbt_project.yml` file from another branch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c0e0205-8084-4d6e-ae84-aa4ac04ec006",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m23:19:20  Running with dbt=1.6.6\n",
      "\u001b[0m23:19:20  Registered adapter: snowflake=1.6.4\n",
      "\u001b[0m23:19:20  Found 45 models, 1 test, 17 sources, 0 exposures, 0 metrics, 489 macros, 0 groups, 0 semantic models\n",
      "\u001b[0m23:19:20  \n",
      "\u001b[0m23:19:22  Concurrency: 20 threads (target='dev')\n",
      "\u001b[0m23:19:22  \n",
      "\u001b[0m23:19:22  1 of 45 START sql table model dl_bronze.brokerage_cash_transaction ............. [RUN]\n",
      "\u001b[0m23:19:22  2 of 45 START sql table model dl_bronze.brokerage_daily_market ................. [RUN]\n",
      "\u001b[0m23:19:22  3 of 45 START sql table model dl_bronze.brokerage_holding_history .............. [RUN]\n",
      "\u001b[0m23:19:22  4 of 45 START sql table model dl_bronze.brokerage_trade ........................ [RUN]\n",
      "\u001b[0m23:19:22  5 of 45 START sql table model dl_bronze.brokerage_trade_history ................ [RUN]\n",
      "\u001b[0m23:19:22  6 of 45 START sql table model dl_bronze.brokerage_watch_history ................ [RUN]\n",
      "\u001b[0m23:19:22  7 of 45 START sql table model dl_bronze.crm_customer_mgmt ...................... [RUN]\n",
      "\u001b[0m23:19:22  8 of 45 START sql table model dl_bronze.finwire_company ........................ [RUN]\n",
      "\u001b[0m23:19:22  9 of 45 START sql table model dl_bronze.finwire_financial ...................... [RUN]\n",
      "\u001b[0m23:19:22  10 of 45 START sql table model dl_bronze.finwire_security ...................... [RUN]\n",
      "\u001b[0m23:19:22  11 of 45 START sql table model dl_bronze.hr_employee ........................... [RUN]\n",
      "\u001b[0m23:19:22  12 of 45 START sql table model dl_bronze.reference_date ........................ [RUN]\n",
      "\u001b[0m23:19:22  13 of 45 START sql table model dl_bronze.reference_industry .................... [RUN]\n",
      "\u001b[0m23:19:22  14 of 45 START sql table model dl_bronze.reference_status_type ................. [RUN]\n",
      "\u001b[0m23:19:22  15 of 45 START sql table model dl_bronze.reference_tax_rate .................... [RUN]\n",
      "\u001b[0m23:19:22  16 of 45 START sql table model dl_bronze.reference_trade_type .................. [RUN]\n",
      "\u001b[0m23:19:22  17 of 45 START sql table model dl_bronze.syndicated_prospect ................... [RUN]\n",
      "\u001b[0m23:19:23  16 of 45 OK created sql table model dl_bronze.reference_trade_type ............. [\u001b[32mSUCCESS 1\u001b[0m in 1.39s]\n",
      "\u001b[0m23:19:23  15 of 45 OK created sql table model dl_bronze.reference_tax_rate ............... [\u001b[32mSUCCESS 1\u001b[0m in 1.54s]\n",
      "\u001b[0m23:19:23  11 of 45 OK created sql table model dl_bronze.hr_employee ...................... [\u001b[32mSUCCESS 1\u001b[0m in 1.67s]\n",
      "\u001b[0m23:19:23  18 of 45 START sql table model dl_silver.employees ............................. [RUN]\n",
      "\u001b[0m23:19:24  13 of 45 OK created sql table model dl_bronze.reference_industry ............... [\u001b[32mSUCCESS 1\u001b[0m in 2.11s]\n",
      "\u001b[0m23:19:24  10 of 45 OK created sql table model dl_bronze.finwire_security ................. [\u001b[32mSUCCESS 1\u001b[0m in 2.21s]\n",
      "\u001b[0m23:19:24  7 of 45 OK created sql table model dl_bronze.crm_customer_mgmt ................. [\u001b[32mSUCCESS 1\u001b[0m in 2.43s]\n",
      "\u001b[0m23:19:24  19 of 45 START sql table model dl_silver.accounts .............................. [RUN]\n",
      "\u001b[0m23:19:24  20 of 45 START sql table model dl_silver.customers ............................. [RUN]\n",
      "\u001b[0m23:19:24  14 of 45 OK created sql table model dl_bronze.reference_status_type ............ [\u001b[32mSUCCESS 1\u001b[0m in 2.82s]\n",
      "\u001b[0m23:19:25  8 of 45 OK created sql table model dl_bronze.finwire_company ................... [\u001b[32mSUCCESS 1\u001b[0m in 3.06s]\n",
      "\u001b[0m23:19:25  21 of 45 START sql table model dl_silver.companies ............................. [RUN]\n",
      "\u001b[0m23:19:25  1 of 45 OK created sql table model dl_bronze.brokerage_cash_transaction ........ [\u001b[32mSUCCESS 1\u001b[0m in 3.27s]\n",
      "\u001b[0m23:19:27  2 of 45 OK created sql table model dl_bronze.brokerage_daily_market ............ [\u001b[32mSUCCESS 1\u001b[0m in 5.09s]\n",
      "\u001b[0m23:19:27  9 of 45 OK created sql table model dl_bronze.finwire_financial ................. [\u001b[32mSUCCESS 1\u001b[0m in 5.07s]\n",
      "\u001b[0m23:19:27  20 of 45 OK created sql table model dl_silver.customers ........................ [\u001b[32mSUCCESS 1\u001b[0m in 2.64s]\n",
      "\u001b[0m23:19:27  22 of 45 START sql table model dl_silver.daily_market .......................... [RUN]\n",
      "\u001b[0m23:19:27  4 of 45 OK created sql table model dl_bronze.brokerage_trade ................... [\u001b[32mSUCCESS 1\u001b[0m in 5.11s]\n",
      "\u001b[0m23:19:27  3 of 45 OK created sql table model dl_bronze.brokerage_holding_history ......... [\u001b[32mSUCCESS 1\u001b[0m in 5.20s]\n",
      "\u001b[0m23:19:27  19 of 45 OK created sql table model dl_silver.accounts ......................... [\u001b[32mSUCCESS 1\u001b[0m in 2.98s]\n",
      "\u001b[0m23:19:27  23 of 45 START sql table model dl_silver.cash_transactions ..................... [RUN]\n",
      "\u001b[0m23:19:28  18 of 45 OK created sql table model dl_silver.employees ........................ [\u001b[32mSUCCESS 1\u001b[0m in 4.21s]\n",
      "\u001b[0m23:19:28  12 of 45 OK created sql table model dl_bronze.reference_date ................... [\u001b[32mSUCCESS 1\u001b[0m in 5.88s]\n",
      "\u001b[0m23:19:28  24 of 45 START sql table model dl_silver.date .................................. [RUN]\n",
      "\u001b[0m23:19:28  25 of 45 START sql table model dl_gold.dim_broker .............................. [RUN]\n",
      "\u001b[0m23:19:28  17 of 45 OK created sql table model dl_bronze.syndicated_prospect .............. [\u001b[32mSUCCESS 1\u001b[0m in 6.37s]\n",
      "\u001b[0m23:19:28  26 of 45 START sql table model dl_gold.dim_customer ............................ [RUN]\n",
      "\u001b[0m23:19:28  21 of 45 OK created sql table model dl_silver.companies ........................ [\u001b[32mSUCCESS 1\u001b[0m in 3.67s]\n",
      "\u001b[0m23:19:28  27 of 45 START sql table model dl_gold.dim_company ............................. [RUN]\n",
      "\u001b[0m23:19:28  28 of 45 START sql table model dl_silver.financials ............................ [RUN]\n",
      "\u001b[0m23:19:28  29 of 45 START sql table model dl_silver.securities ............................ [RUN]\n",
      "\u001b[0m23:19:29  6 of 45 OK created sql table model dl_bronze.brokerage_watch_history ........... [\u001b[32mSUCCESS 1\u001b[0m in 7.12s]\n",
      "\u001b[0m23:19:29  24 of 45 OK created sql table model dl_silver.date ............................. [\u001b[32mSUCCESS 1\u001b[0m in 1.69s]\n",
      "\u001b[0m23:19:29  30 of 45 START sql table model dl_gold.dim_date ................................ [RUN]\n",
      "\u001b[0m23:19:29  5 of 45 OK created sql table model dl_bronze.brokerage_trade_history ........... [\u001b[32mSUCCESS 1\u001b[0m in 7.70s]\n",
      "\u001b[0m23:19:29  31 of 45 START sql table model dl_silver.trades_history ........................ [RUN]\n",
      "\u001b[0m23:19:30  25 of 45 OK created sql table model dl_gold.dim_broker ......................... [\u001b[32mSUCCESS 1\u001b[0m in 2.05s]\n",
      "\u001b[0m23:19:31  27 of 45 OK created sql table model dl_gold.dim_company ........................ [\u001b[32mSUCCESS 1\u001b[0m in 2.10s]\n",
      "\u001b[0m23:19:31  29 of 45 OK created sql table model dl_silver.securities ....................... [\u001b[32mSUCCESS 1\u001b[0m in 2.34s]\n",
      "\u001b[0m23:19:31  32 of 45 START sql table model dl_gold.dim_security ............................ [RUN]\n",
      "\u001b[0m23:19:31  33 of 45 START sql table model dl_silver.watches_history ....................... [RUN]\n",
      "\u001b[0m23:19:31  23 of 45 OK created sql table model dl_silver.cash_transactions ................ [\u001b[32mSUCCESS 1\u001b[0m in 3.74s]\n",
      "\u001b[0m23:19:31  30 of 45 OK created sql table model dl_gold.dim_date ........................... [\u001b[32mSUCCESS 1\u001b[0m in 1.66s]\n",
      "\u001b[0m23:19:31  26 of 45 OK created sql table model dl_gold.dim_customer ....................... [\u001b[32mSUCCESS 1\u001b[0m in 3.17s]\n",
      "\u001b[0m23:19:31  34 of 45 START sql table model dl_gold.dim_account ............................. [RUN]\n",
      "\u001b[0m23:19:32  28 of 45 OK created sql table model dl_silver.financials ....................... [\u001b[32mSUCCESS 1\u001b[0m in 3.95s]\n",
      "\u001b[0m23:19:33  32 of 45 OK created sql table model dl_gold.dim_security ....................... [\u001b[32mSUCCESS 1\u001b[0m in 2.15s]\n",
      "\u001b[0m23:19:34  34 of 45 OK created sql table model dl_gold.dim_account ........................ [\u001b[32mSUCCESS 1\u001b[0m in 3.21s]\n",
      "\u001b[0m23:19:34  35 of 45 START sql table model dl_gold.fact_cash_transactions .................. [RUN]\n",
      "\u001b[0m23:19:36  22 of 45 OK created sql table model dl_silver.daily_market ..................... [\u001b[32mSUCCESS 1\u001b[0m in 9.26s]\n",
      "\u001b[0m23:19:36  36 of 45 START sql table model dl_gold.fact_market_history ..................... [RUN]\n",
      "\u001b[0m23:19:38  35 of 45 OK created sql table model dl_gold.fact_cash_transactions ............. [\u001b[32mSUCCESS 1\u001b[0m in 3.82s]\n",
      "\u001b[0m23:19:38  37 of 45 START sql table model dl_gold.fact_cash_balances ...................... [RUN]\n",
      "\u001b[0m23:19:38  31 of 45 OK created sql table model dl_silver.trades_history ................... [\u001b[32mSUCCESS 1\u001b[0m in 9.02s]\n",
      "\u001b[0m23:19:38  38 of 45 START sql table model dl_gold.dim_trade ............................... [RUN]\n",
      "\u001b[0m23:19:38  39 of 45 START sql table model dl_silver.trades ................................ [RUN]\n",
      "\u001b[0m23:19:41  37 of 45 OK created sql table model dl_gold.fact_cash_balances ................. [\u001b[32mSUCCESS 1\u001b[0m in 3.08s]\n",
      "\u001b[0m23:19:42  33 of 45 OK created sql table model dl_silver.watches_history .................. [\u001b[32mSUCCESS 1\u001b[0m in 11.04s]\n",
      "\u001b[0m23:19:42  40 of 45 START sql table model dl_silver.watches ............................... [RUN]\n",
      "\u001b[0m23:19:42  38 of 45 OK created sql table model dl_gold.dim_trade .......................... [\u001b[32mSUCCESS 1\u001b[0m in 3.50s]\n",
      "\u001b[0m23:19:43  39 of 45 OK created sql table model dl_silver.trades ........................... [\u001b[32mSUCCESS 1\u001b[0m in 4.85s]\n",
      "\u001b[0m23:19:43  41 of 45 START sql table model dl_silver.holdings_history ...................... [RUN]\n",
      "\u001b[0m23:19:43  42 of 45 START sql table model dl_gold.fact_trade .............................. [RUN]\n",
      "\u001b[0m23:19:46  41 of 45 OK created sql table model dl_silver.holdings_history ................. [\u001b[32mSUCCESS 1\u001b[0m in 2.91s]\n",
      "\u001b[0m23:19:46  43 of 45 START sql table model dl_gold.fact_holdings ........................... [RUN]\n",
      "\u001b[0m23:19:50  40 of 45 OK created sql table model dl_silver.watches .......................... [\u001b[32mSUCCESS 1\u001b[0m in 8.23s]\n",
      "\u001b[0m23:19:50  44 of 45 START sql table model dl_gold.fact_watches ............................ [RUN]\n",
      "\u001b[0m23:19:53  42 of 45 OK created sql table model dl_gold.fact_trade ......................... [\u001b[32mSUCCESS 1\u001b[0m in 9.86s]\n",
      "\u001b[0m23:19:53  45 of 45 START test fact_trade__unique_trade ................................... [RUN]\n",
      "\u001b[0m23:19:54  45 of 45 PASS fact_trade__unique_trade ......................................... [\u001b[32mPASS\u001b[0m in 1.00s]\n",
      "\u001b[0m23:19:55  43 of 45 OK created sql table model dl_gold.fact_holdings ...................... [\u001b[32mSUCCESS 1\u001b[0m in 8.55s]\n",
      "\u001b[0m23:19:56  44 of 45 OK created sql table model dl_gold.fact_watches ....................... [\u001b[32mSUCCESS 1\u001b[0m in 5.55s]\n",
      "\u001b[0m23:20:42  36 of 45 OK created sql table model dl_gold.fact_market_history ................ [\u001b[32mSUCCESS 1\u001b[0m in 65.67s]\n",
      "\u001b[0m23:20:42  \n",
      "\u001b[0m23:20:42  Finished running 44 table models, 1 test in 0 hours 1 minutes and 21.20 seconds (81.20s).\n",
      "\u001b[0m23:20:42  \n",
      "\u001b[0m23:20:42  \u001b[32mCompleted successfully\u001b[0m\n",
      "\u001b[0m23:20:42  \n",
      "\u001b[0m23:20:42  Done. PASS=45 WARN=0 ERROR=0 SKIP=0 TOTAL=45\n"
     ]
    }
   ],
   "source": [
    "!git restore --source standard-tables -- dbt_project.yml\n",
    "!dbt build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050a1522-b180-4f64-b8ed-f969fb4a2250",
   "metadata": {},
   "source": [
    "# Now we'll restore our original `dbt_project.yml` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "831221fb-14ac-44f0-9921-eee5a5d52e65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated 1 path from the index\n"
     ]
    }
   ],
   "source": [
    "!git checkout dbt_project.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469f485d-792c-46df-906f-cd09f364d7d0",
   "metadata": {},
   "source": [
    "# We can see all that's required to enable dynamic tables in our `dbt_project.yml` file:\n",
    "\n",
    "```yaml\n",
    "models:\n",
    "  dbt_tpcdi:\n",
    "    example:\n",
    "      +materialized: view\n",
    "    bronze:\n",
    "      +schema: bronze\n",
    "      +materialized: dynamic_table\n",
    "      +snowflake_warehouse: tpcdi_xlarge\n",
    "      +target_lag: '10 minutes'\n",
    "    silver:\n",
    "      +schema: silver\n",
    "      +materialized: dynamic_table\n",
    "      +snowflake_warehouse: tpcdi_xlarge\n",
    "      +target_lag: '10 minutes'\n",
    "    gold:\n",
    "      +schema: gold\n",
    "      +materialized: dynamic_table\n",
    "      +snowflake_warehouse: tpcdi_xlarge\n",
    "      +target_lag: '20 minutes'\n",
    "    work:\n",
    "      +schema: work\n",
    "      +materialized: dynamic_table\n",
    "      +snowflake_warehouse: tpcdi_xlarge\n",
    "      +target_lag: downstream\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "420db6a7-ce06-4638-a3a5-1ac16aff2fc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m23:23:01  Running with dbt=1.6.6\n",
      "\u001b[0m23:23:01  Registered adapter: snowflake=1.6.4\n",
      "\u001b[0m23:23:01  Unable to do partial parsing because a project config has changed\n",
      "\u001b[0m23:23:02  Found 45 models, 1 test, 17 sources, 0 exposures, 0 metrics, 489 macros, 0 groups, 0 semantic models\n",
      "\u001b[0m23:23:02  \n",
      "\u001b[0m23:23:05  Concurrency: 20 threads (target='dev')\n",
      "\u001b[0m23:23:05  \n",
      "\u001b[0m23:23:05  1 of 46 START sql dynamic_table model dl_bronze.brokerage_cash_transaction ..... [RUN]\n",
      "\u001b[0m23:23:05  2 of 46 START sql dynamic_table model dl_bronze.brokerage_daily_market ......... [RUN]\n",
      "\u001b[0m23:23:05  3 of 46 START sql dynamic_table model dl_bronze.brokerage_holding_history ...... [RUN]\n",
      "\u001b[0m23:23:05  4 of 46 START sql dynamic_table model dl_bronze.brokerage_trade ................ [RUN]\n",
      "\u001b[0m23:23:05  5 of 46 START sql dynamic_table model dl_bronze.brokerage_trade_history ........ [RUN]\n",
      "\u001b[0m23:23:05  6 of 46 START sql dynamic_table model dl_bronze.brokerage_watch_history ........ [RUN]\n",
      "\u001b[0m23:23:05  7 of 46 START sql dynamic_table model dl_bronze.crm_customer_mgmt .............. [RUN]\n",
      "\u001b[0m23:23:05  8 of 46 START sql dynamic_table model dl_bronze.finwire_company ................ [RUN]\n",
      "\u001b[0m23:23:05  9 of 46 START sql dynamic_table model dl_bronze.finwire_financial .............. [RUN]\n",
      "\u001b[0m23:23:05  10 of 46 START sql dynamic_table model dl_bronze.finwire_security .............. [RUN]\n",
      "\u001b[0m23:23:05  11 of 46 START sql dynamic_table model dl_bronze.hr_employee ................... [RUN]\n",
      "\u001b[0m23:23:05  12 of 46 START sql dynamic_table model dl_bronze.reference_date ................ [RUN]\n",
      "\u001b[0m23:23:05  13 of 46 START sql dynamic_table model dl_bronze.reference_industry ............ [RUN]\n",
      "\u001b[0m23:23:05  14 of 46 START sql dynamic_table model dl_bronze.reference_status_type ......... [RUN]\n",
      "\u001b[0m23:23:05  15 of 46 START sql dynamic_table model dl_bronze.reference_tax_rate ............ [RUN]\n",
      "\u001b[0m23:23:05  16 of 46 START sql dynamic_table model dl_bronze.reference_trade_type .......... [RUN]\n",
      "\u001b[0m23:23:05  17 of 46 START sql dynamic_table model dl_bronze.syndicated_prospect ........... [RUN]\n",
      "\u001b[0m23:23:07  13 of 46 OK created sql dynamic_table model dl_bronze.reference_industry ....... [\u001b[32mSUCCESS 1\u001b[0m in 2.32s]\n",
      "\u001b[0m23:23:07  15 of 46 OK created sql dynamic_table model dl_bronze.reference_tax_rate ....... [\u001b[32mSUCCESS 1\u001b[0m in 2.33s]\n",
      "\u001b[0m23:23:07  16 of 46 OK created sql dynamic_table model dl_bronze.reference_trade_type ..... [\u001b[32mSUCCESS 1\u001b[0m in 2.80s]\n",
      "\u001b[0m23:23:07  12 of 46 OK created sql dynamic_table model dl_bronze.reference_date ........... [\u001b[32mSUCCESS 1\u001b[0m in 2.83s]\n",
      "\u001b[0m23:23:07  18 of 46 START sql dynamic_table model dl_silver.date .......................... [RUN]\n",
      "\u001b[0m23:23:08  14 of 46 OK created sql dynamic_table model dl_bronze.reference_status_type .... [\u001b[32mSUCCESS 1\u001b[0m in 3.18s]\n",
      "\u001b[0m23:23:08  8 of 46 OK created sql dynamic_table model dl_bronze.finwire_company ........... [\u001b[32mSUCCESS 1\u001b[0m in 3.65s]\n",
      "\u001b[0m23:23:08  10 of 46 OK created sql dynamic_table model dl_bronze.finwire_security ......... [\u001b[32mSUCCESS 1\u001b[0m in 3.65s]\n",
      "\u001b[0m23:23:08  19 of 46 START sql dynamic_table model dl_silver.companies ..................... [RUN]\n",
      "\u001b[0m23:23:09  9 of 46 OK created sql dynamic_table model dl_bronze.finwire_financial ......... [\u001b[32mSUCCESS 1\u001b[0m in 4.21s]\n",
      "\u001b[0m23:23:09  7 of 46 OK created sql dynamic_table model dl_bronze.crm_customer_mgmt ......... [\u001b[32mSUCCESS 1\u001b[0m in 4.24s]\n",
      "\u001b[0m23:23:09  20 of 46 START sql dynamic_table model dl_silver.accounts ...................... [RUN]\n",
      "\u001b[0m23:23:09  21 of 46 START sql dynamic_table model dl_silver.customers ..................... [RUN]\n",
      "\u001b[0m23:23:09  17 of 46 OK created sql dynamic_table model dl_bronze.syndicated_prospect ...... [\u001b[32mSUCCESS 1\u001b[0m in 4.78s]\n",
      "\u001b[0m23:23:10  11 of 46 OK created sql dynamic_table model dl_bronze.hr_employee .............. [\u001b[32mSUCCESS 1\u001b[0m in 5.18s]\n",
      "\u001b[0m23:23:10  22 of 46 START sql dynamic_table model dl_silver.employees ..................... [RUN]\n",
      "\u001b[0m23:23:11  18 of 46 OK created sql dynamic_table model dl_silver.date ..................... [\u001b[32mSUCCESS 1\u001b[0m in 3.19s]\n",
      "\u001b[0m23:23:11  23 of 46 START sql dynamic_table model dl_gold.dim_date ........................ [RUN]\n",
      "\u001b[0m23:23:12  19 of 46 OK created sql dynamic_table model dl_silver.companies ................ [\u001b[32mSUCCESS 1\u001b[0m in 3.63s]\n",
      "\u001b[0m23:23:12  24 of 46 START sql dynamic_table model dl_gold.dim_company ..................... [RUN]\n",
      "\u001b[0m23:23:12  25 of 46 START sql dynamic_table model dl_silver.financials .................... [RUN]\n",
      "\u001b[0m23:23:12  26 of 46 START sql dynamic_table model dl_silver.securities .................... [RUN]\n",
      "\u001b[0m23:23:12  1 of 46 OK created sql dynamic_table model dl_bronze.brokerage_cash_transaction  [\u001b[32mSUCCESS 1\u001b[0m in 7.50s]\n",
      "\u001b[0m23:23:13  20 of 46 OK created sql dynamic_table model dl_silver.accounts ................. [\u001b[32mSUCCESS 1\u001b[0m in 3.60s]\n",
      "\u001b[0m23:23:13  27 of 46 START sql dynamic_table model dl_silver.cash_transactions ............. [RUN]\n",
      "\u001b[0m23:23:13  3 of 46 OK created sql dynamic_table model dl_bronze.brokerage_holding_history . [\u001b[32mSUCCESS 1\u001b[0m in 8.55s]\n",
      "\u001b[0m23:23:13  21 of 46 OK created sql dynamic_table model dl_silver.customers ................ [\u001b[32mSUCCESS 1\u001b[0m in 4.42s]\n",
      "\u001b[0m23:23:13  28 of 46 START sql dynamic_table model dl_gold.dim_customer .................... [RUN]\n",
      "\u001b[0m23:23:14  22 of 46 OK created sql dynamic_table model dl_silver.employees ................ [\u001b[32mSUCCESS 1\u001b[0m in 3.77s]\n",
      "\u001b[0m23:23:14  29 of 46 START sql dynamic_table model dl_gold.dim_broker ...................... [RUN]\n",
      "\u001b[0m23:23:14  23 of 46 OK created sql dynamic_table model dl_gold.dim_date ................... [\u001b[32mSUCCESS 1\u001b[0m in 3.80s]\n",
      "\u001b[0m23:23:16  4 of 46 OK created sql dynamic_table model dl_bronze.brokerage_trade ........... [\u001b[32mSUCCESS 1\u001b[0m in 10.88s]\n",
      "\u001b[0m23:23:16  5 of 46 OK created sql dynamic_table model dl_bronze.brokerage_trade_history ... [\u001b[32mSUCCESS 1\u001b[0m in 10.92s]\n",
      "\u001b[0m23:23:16  30 of 46 START sql dynamic_table model dl_silver.trades_history ................ [RUN]\n",
      "\u001b[0m23:23:16  6 of 46 OK created sql dynamic_table model dl_bronze.brokerage_watch_history ... [\u001b[32mSUCCESS 1\u001b[0m in 10.97s]\n",
      "\u001b[0m23:23:17  24 of 46 OK created sql dynamic_table model dl_gold.dim_company ................ [\u001b[32mSUCCESS 1\u001b[0m in 5.28s]\n",
      "\u001b[0m23:23:18  29 of 46 OK created sql dynamic_table model dl_gold.dim_broker ................. [\u001b[32mSUCCESS 1\u001b[0m in 3.89s]\n",
      "\u001b[0m23:23:18  26 of 46 OK created sql dynamic_table model dl_silver.securities ............... [\u001b[32mSUCCESS 1\u001b[0m in 6.02s]\n",
      "\u001b[0m23:23:18  31 of 46 START sql dynamic_table model dl_gold.dim_security .................... [RUN]\n",
      "\u001b[0m23:23:18  32 of 46 START sql dynamic_table model dl_silver.watches_history ............... [RUN]\n",
      "\u001b[0m23:23:18  2 of 46 OK created sql dynamic_table model dl_bronze.brokerage_daily_market .... [\u001b[32mSUCCESS 1\u001b[0m in 13.48s]\n",
      "\u001b[0m23:23:18  33 of 46 START sql dynamic_table model dl_silver.daily_market .................. [RUN]\n",
      "\u001b[0m23:23:19  27 of 46 OK created sql dynamic_table model dl_silver.cash_transactions ........ [\u001b[32mSUCCESS 1\u001b[0m in 6.49s]\n",
      "\u001b[0m23:23:19  28 of 46 OK created sql dynamic_table model dl_gold.dim_customer ............... [\u001b[32mSUCCESS 1\u001b[0m in 5.68s]\n",
      "\u001b[0m23:23:19  34 of 46 START sql dynamic_table model dl_gold.dim_account ..................... [RUN]\n",
      "\u001b[0m23:23:19  25 of 46 OK created sql dynamic_table model dl_silver.financials ............... [\u001b[32mSUCCESS 1\u001b[0m in 7.22s]\n",
      "\u001b[0m23:23:19  35 of 46 START sql dynamic_table model dl_work.wrk_company_financials .......... [RUN]\n",
      "\u001b[0m23:23:25  31 of 46 OK created sql dynamic_table model dl_gold.dim_security ............... [\u001b[32mSUCCESS 1\u001b[0m in 6.70s]\n",
      "\u001b[0m23:23:26  35 of 46 OK created sql dynamic_table model dl_work.wrk_company_financials ..... [\u001b[32mSUCCESS 1\u001b[0m in 6.53s]\n",
      "\u001b[0m23:23:26  34 of 46 OK created sql dynamic_table model dl_gold.dim_account ................ [\u001b[32mSUCCESS 1\u001b[0m in 6.82s]\n",
      "\u001b[0m23:23:26  36 of 46 START sql dynamic_table model dl_gold.fact_cash_transactions .......... [RUN]\n",
      "\u001b[0m23:23:27  33 of 46 OK created sql dynamic_table model dl_silver.daily_market ............. [\u001b[32mSUCCESS 1\u001b[0m in 8.92s]\n",
      "\u001b[0m23:23:27  37 of 46 START sql dynamic_table model dl_gold.fact_market_history ............. [RUN]\n",
      "\u001b[0m23:23:27  32 of 46 OK created sql dynamic_table model dl_silver.watches_history .......... [\u001b[32mSUCCESS 1\u001b[0m in 9.08s]\n",
      "\u001b[0m23:23:27  38 of 46 START sql dynamic_table model dl_silver.watches ....................... [RUN]\n",
      "\u001b[0m23:23:28  30 of 46 OK created sql dynamic_table model dl_silver.trades_history ........... [\u001b[32mSUCCESS 1\u001b[0m in 12.78s]\n",
      "\u001b[0m23:23:28  39 of 46 START sql dynamic_table model dl_gold.dim_trade ....................... [RUN]\n",
      "\u001b[0m23:23:28  40 of 46 START sql dynamic_table model dl_silver.trades ........................ [RUN]\n",
      "\u001b[0m23:23:33  36 of 46 OK created sql dynamic_table model dl_gold.fact_cash_transactions ..... [\u001b[32mSUCCESS 1\u001b[0m in 7.36s]\n",
      "\u001b[0m23:23:33  41 of 46 START sql dynamic_table model dl_gold.fact_cash_balances .............. [RUN]\n",
      "\u001b[0m23:23:34  38 of 46 OK created sql dynamic_table model dl_silver.watches .................. [\u001b[32mSUCCESS 1\u001b[0m in 7.30s]\n",
      "\u001b[0m23:23:34  42 of 46 START sql dynamic_table model dl_gold.fact_watches .................... [RUN]\n",
      "\u001b[0m23:23:35  39 of 46 OK created sql dynamic_table model dl_gold.dim_trade .................. [\u001b[32mSUCCESS 1\u001b[0m in 6.84s]\n",
      "\u001b[0m23:23:40  40 of 46 OK created sql dynamic_table model dl_silver.trades ................... [\u001b[32mSUCCESS 1\u001b[0m in 11.45s]\n",
      "\u001b[0m23:23:40  43 of 46 START sql dynamic_table model dl_silver.holdings_history .............. [RUN]\n",
      "\u001b[0m23:23:40  44 of 46 START sql dynamic_table model dl_gold.fact_trade ...................... [RUN]\n",
      "\u001b[0m23:23:43  42 of 46 OK created sql dynamic_table model dl_gold.fact_watches ............... [\u001b[32mSUCCESS 1\u001b[0m in 9.08s]\n",
      "\u001b[0m23:23:45  41 of 46 OK created sql dynamic_table model dl_gold.fact_cash_balances ......... [\u001b[32mSUCCESS 1\u001b[0m in 12.18s]\n",
      "\u001b[0m23:23:49  43 of 46 OK created sql dynamic_table model dl_silver.holdings_history ......... [\u001b[32mSUCCESS 1\u001b[0m in 9.64s]\n",
      "\u001b[0m23:23:49  45 of 46 START sql dynamic_table model dl_gold.fact_holdings ................... [RUN]\n",
      "\u001b[0m23:24:01  44 of 46 OK created sql dynamic_table model dl_gold.fact_trade ................. [\u001b[32mSUCCESS 1\u001b[0m in 21.67s]\n",
      "\u001b[0m23:24:02  46 of 46 START test fact_trade__unique_trade ................................... [RUN]\n",
      "\u001b[0m23:24:03  46 of 46 PASS fact_trade__unique_trade ......................................... [\u001b[32mPASS\u001b[0m in 1.19s]\n",
      "\u001b[0m23:24:03  45 of 46 OK created sql dynamic_table model dl_gold.fact_holdings .............. [\u001b[32mSUCCESS 1\u001b[0m in 13.67s]\n",
      "\u001b[0m23:24:45  37 of 46 OK created sql dynamic_table model dl_gold.fact_market_history ........ [\u001b[32mSUCCESS 1\u001b[0m in 77.48s]\n",
      "\u001b[0m23:24:45  \n",
      "\u001b[0m23:24:45  Finished running 45 dynamic_table models, 1 test in 0 hours 1 minutes and 42.82 seconds (102.82s).\n",
      "\u001b[0m23:24:45  \n",
      "\u001b[0m23:24:45  \u001b[32mCompleted successfully\u001b[0m\n",
      "\u001b[0m23:24:45  \n",
      "\u001b[0m23:24:45  Done. PASS=46 WARN=0 ERROR=0 SKIP=0 TOTAL=46\n"
     ]
    }
   ],
   "source": [
    "!dbt build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5c05ca-a924-4549-ba19-d5fa61df5434",
   "metadata": {},
   "source": [
    "Click this link to open results:\n",
    "\n",
    "[Snowflake UI](https://app.snowflake.com/cxmdykz/hib36835/#/data/databases/TPCDI_DT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb79852",
   "metadata": {},
   "source": [
    "# dbt also has Tests.\n",
    "\n",
    "# We can run them when we create the Dynamic Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a62811a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m23:28:07  Running with dbt=1.6.6\n",
      "\u001b[0m23:28:08  Registered adapter: snowflake=1.6.4\n",
      "\u001b[0m23:28:08  Found 45 models, 1 test, 17 sources, 0 exposures, 0 metrics, 489 macros, 0 groups, 0 semantic models\n",
      "\u001b[0m23:28:08  \n",
      "\u001b[0m23:28:10  Concurrency: 20 threads (target='dev')\n",
      "\u001b[0m23:28:10  \n",
      "\u001b[0m23:28:10  1 of 2 START sql dynamic_table model dl_gold.fact_trade ........................ [RUN]\n",
      "\u001b[0m23:28:12  1 of 2 OK created sql dynamic_table model dl_gold.fact_trade ................... [\u001b[32mSUCCESS 1\u001b[0m in 2.19s]\n",
      "\u001b[0m23:28:12  2 of 2 START test fact_trade__unique_trade ..................................... [RUN]\n",
      "\u001b[0m23:28:12  2 of 2 PASS fact_trade__unique_trade ........................................... [\u001b[32mPASS\u001b[0m in 0.66s]\n",
      "\u001b[0m23:28:12  \n",
      "\u001b[0m23:28:12  Finished running 1 dynamic_table model, 1 test in 0 hours 0 minutes and 4.60 seconds (4.60s).\n",
      "\u001b[0m23:28:12  \n",
      "\u001b[0m23:28:12  \u001b[32mCompleted successfully\u001b[0m\n",
      "\u001b[0m23:28:12  \n",
      "\u001b[0m23:28:12  Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2\n"
     ]
    }
   ],
   "source": [
    "!dbt build --select fact_trade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d564eded",
   "metadata": {},
   "source": [
    "# Or we can schedule them to run periodically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf40309e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m23:29:18  Running with dbt=1.6.6\n",
      "\u001b[0m23:29:18  Registered adapter: snowflake=1.6.4\n",
      "\u001b[0m23:29:19  Found 45 models, 1 test, 17 sources, 0 exposures, 0 metrics, 489 macros, 0 groups, 0 semantic models\n",
      "\u001b[0m23:29:19  \n",
      "\u001b[0m23:29:19  Concurrency: 20 threads (target='dev')\n",
      "\u001b[0m23:29:19  \n",
      "\u001b[0m23:29:19  1 of 1 START test fact_trade__unique_trade ..................................... [RUN]\n",
      "\u001b[0m23:29:20  1 of 1 PASS fact_trade__unique_trade ........................................... [\u001b[32mPASS\u001b[0m in 0.57s]\n",
      "\u001b[0m23:29:20  \n",
      "\u001b[0m23:29:20  Finished running 1 test in 0 hours 0 minutes and 1.29 seconds (1.29s).\n",
      "\u001b[0m23:29:20  \n",
      "\u001b[0m23:29:20  \u001b[32mCompleted successfully\u001b[0m\n",
      "\u001b[0m23:29:20  \n",
      "\u001b[0m23:29:20  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1\n"
     ]
    }
   ],
   "source": [
    "!dbt test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3f442b",
   "metadata": {},
   "source": [
    "# dbt Cloud will need to be more than just a job scheduler, which it already is.\n",
    "\n",
    "1. Cloud development environment for those that prefer it (Needs to get better).\n",
    "1. CI/CD workflows for promoting Dynamic Table changes into Production.\n",
    "1. Perhaps there's promise in the Semantic Layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22101a49",
   "metadata": {},
   "source": [
    "# Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c6a912a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema dl_gold dropped.\n",
      "Schema dl_silver dropped.\n",
      "Schema dl_bronze dropped.\n",
      "Schema dl_work dropped.\n"
     ]
    }
   ],
   "source": [
    "!python tpcdi.py drop-schema --schema dl_gold\n",
    "!python tpcdi.py drop-schema --schema dl_silver\n",
    "!python tpcdi.py drop-schema --schema dl_bronze\n",
    "!python tpcdi.py drop-schema --schema dl_work"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
